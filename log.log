[framework] 2020-09-22 19:00:16,030 - org.apache.kafka.clients.producer.ProducerConfig -0    [main] INFO  org.apache.kafka.clients.producer.ProducerConfig  - ProducerConfig values: 
	acks = all
	batch.size = 1000
	bootstrap.servers = [Kafka-1:9092]
	buffer.memory = 2048000
	client.dns.lookup = default
	client.id = DemoProducer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class cn.neyzoter.module.kafka.AllocationPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[framework] 2020-09-22 19:00:16,133 - org.apache.kafka.common.metrics.Metrics -103  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bufferpool-wait-time
[framework] 2020-09-22 19:00:16,143 - org.apache.kafka.common.metrics.Metrics -113  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name buffer-exhausted-records
[framework] 2020-09-22 19:00:16,157 - org.apache.kafka.common.metrics.Metrics -127  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name errors
[framework] 2020-09-22 19:00:16,166 - org.apache.kafka.common.metrics.Metrics -136  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name produce-throttle-time
[framework] 2020-09-22 19:00:16,180 - org.apache.kafka.common.metrics.Metrics -150  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-closed:
[framework] 2020-09-22 19:00:16,181 - org.apache.kafka.common.metrics.Metrics -151  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-created:
[framework] 2020-09-22 19:00:16,182 - org.apache.kafka.common.metrics.Metrics -152  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication:
[framework] 2020-09-22 19:00:16,182 - org.apache.kafka.common.metrics.Metrics -152  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-reauthentication:
[framework] 2020-09-22 19:00:16,183 - org.apache.kafka.common.metrics.Metrics -153  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication-no-reauth:
[framework] 2020-09-22 19:00:16,185 - org.apache.kafka.common.metrics.Metrics -155  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-authentication:
[framework] 2020-09-22 19:00:16,186 - org.apache.kafka.common.metrics.Metrics -156  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-reauthentication:
[framework] 2020-09-22 19:00:16,186 - org.apache.kafka.common.metrics.Metrics -156  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name reauthentication-latency:
[framework] 2020-09-22 19:00:16,187 - org.apache.kafka.common.metrics.Metrics -157  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent-received:
[framework] 2020-09-22 19:00:16,188 - org.apache.kafka.common.metrics.Metrics -158  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent:
[framework] 2020-09-22 19:00:16,189 - org.apache.kafka.common.metrics.Metrics -159  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-received:
[framework] 2020-09-22 19:00:16,189 - org.apache.kafka.common.metrics.Metrics -159  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name select-time:
[framework] 2020-09-22 19:00:16,190 - org.apache.kafka.common.metrics.Metrics -160  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name io-time:
[framework] 2020-09-22 19:00:16,241 - org.apache.kafka.common.metrics.Metrics -211  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name batch-size
[framework] 2020-09-22 19:00:16,241 - org.apache.kafka.common.metrics.Metrics -211  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name compression-rate
[framework] 2020-09-22 19:00:16,241 - org.apache.kafka.common.metrics.Metrics -211  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name queue-time
[framework] 2020-09-22 19:00:16,241 - org.apache.kafka.common.metrics.Metrics -211  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name request-time
[framework] 2020-09-22 19:00:16,242 - org.apache.kafka.common.metrics.Metrics -212  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-per-request
[framework] 2020-09-22 19:00:16,242 - org.apache.kafka.common.metrics.Metrics -212  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name record-retries
[framework] 2020-09-22 19:00:16,242 - org.apache.kafka.common.metrics.Metrics -212  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name record-size
[framework] 2020-09-22 19:00:16,245 - org.apache.kafka.common.metrics.Metrics -215  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name batch-split-rate
[framework] 2020-09-22 19:00:16,246 - org.apache.kafka.clients.producer.internals.Sender -216  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.producer.internals.Sender  - [Producer clientId=DemoProducer] Starting Kafka producer I/O thread.
[framework] 2020-09-22 19:00:16,248 - org.apache.kafka.common.utils.AppInfoParser -218  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka version: 2.3.0
[framework] 2020-09-22 19:00:16,248 - org.apache.kafka.common.utils.AppInfoParser -218  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka commitId: fc1aaa116b661c8a
[framework] 2020-09-22 19:00:16,249 - org.apache.kafka.common.utils.AppInfoParser -219  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka startTimeMs: 1600772416246
[framework] 2020-09-22 19:00:16,251 - org.apache.kafka.clients.producer.KafkaProducer -221  [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer  - [Producer clientId=DemoProducer] Kafka producer started
[framework] 2020-09-22 19:00:16,261 - org.apache.kafka.clients.NetworkClient -231  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initialize connection to node Kafka-1:9092 (id: -1 rack: null) for sending metadata request
[framework] 2020-09-22 19:00:16,262 - org.apache.kafka.clients.NetworkClient -232  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating connection to node Kafka-1:9092 (id: -1 rack: null) using address Kafka-1/47.110.251.155
[framework] 2020-09-22 19:00:16,292 - org.apache.kafka.common.metrics.Metrics -262  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-sent
[framework] 2020-09-22 19:00:16,293 - org.apache.kafka.common.metrics.Metrics -263  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-received
[framework] 2020-09-22 19:00:16,294 - org.apache.kafka.common.metrics.Metrics -264  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.latency
[framework] 2020-09-22 19:00:16,297 - org.apache.kafka.common.network.Selector -267  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.network.Selector  - [Producer clientId=DemoProducer] Created socket with SO_RCVBUF = 32832, SO_SNDBUF = 131328, SO_TIMEOUT = 0 to node -1
[framework] 2020-09-22 19:00:16,309 - kafka.utils.Log4jControllerRegistration$ -279  [main] INFO  kafka.utils.Log4jControllerRegistration$  - Registered kafka:type=kafka.Log4jController MBean
[framework] 2020-09-22 19:00:16,317 - org.apache.kafka.clients.consumer.ConsumerConfig -287  [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig  - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [Kafka-1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = Commit2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = DemoConsumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[framework] 2020-09-22 19:00:16,318 - org.apache.kafka.clients.consumer.KafkaConsumer -288  [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=Commit2, groupId=DemoConsumer] Initializing the Kafka consumer
[framework] 2020-09-22 19:00:16,333 - org.apache.kafka.common.metrics.Metrics -303  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-throttle-time
[framework] 2020-09-22 19:00:16,333 - org.apache.kafka.common.metrics.Metrics -303  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-closed:
[framework] 2020-09-22 19:00:16,333 - org.apache.kafka.common.metrics.Metrics -303  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-created:
[framework] 2020-09-22 19:00:16,334 - org.apache.kafka.common.metrics.Metrics -304  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication:
[framework] 2020-09-22 19:00:16,334 - org.apache.kafka.common.metrics.Metrics -304  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-reauthentication:
[framework] 2020-09-22 19:00:16,334 - org.apache.kafka.common.metrics.Metrics -304  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication-no-reauth:
[framework] 2020-09-22 19:00:16,334 - org.apache.kafka.common.metrics.Metrics -304  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-authentication:
[framework] 2020-09-22 19:00:16,335 - org.apache.kafka.common.metrics.Metrics -305  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-reauthentication:
[framework] 2020-09-22 19:00:16,336 - org.apache.kafka.common.metrics.Metrics -306  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name reauthentication-latency:
[framework] 2020-09-22 19:00:16,336 - org.apache.kafka.common.metrics.Metrics -306  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent-received:
[framework] 2020-09-22 19:00:16,336 - org.apache.kafka.common.metrics.Metrics -306  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent:
[framework] 2020-09-22 19:00:16,337 - org.apache.kafka.common.metrics.Metrics -307  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-received:
[framework] 2020-09-22 19:00:16,338 - org.apache.kafka.common.metrics.Metrics -308  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name select-time:
[framework] 2020-09-22 19:00:16,339 - org.apache.kafka.common.metrics.Metrics -309  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name io-time:
[framework] 2020-09-22 19:00:16,352 - org.apache.kafka.common.metrics.Metrics -322  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name heartbeat-latency
[framework] 2020-09-22 19:00:16,352 - org.apache.kafka.common.metrics.Metrics -322  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name join-latency
[framework] 2020-09-22 19:00:16,353 - org.apache.kafka.common.metrics.Metrics -323  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name sync-latency
[framework] 2020-09-22 19:00:16,355 - org.apache.kafka.common.metrics.Metrics -325  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name commit-latency
[framework] 2020-09-22 19:00:16,358 - org.apache.kafka.common.metrics.Metrics -328  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-fetched
[framework] 2020-09-22 19:00:16,358 - org.apache.kafka.common.metrics.Metrics -328  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-fetched
[framework] 2020-09-22 19:00:16,358 - org.apache.kafka.common.metrics.Metrics -328  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-latency
[framework] 2020-09-22 19:00:16,359 - org.apache.kafka.common.metrics.Metrics -329  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lag
[framework] 2020-09-22 19:00:16,359 - org.apache.kafka.common.metrics.Metrics -329  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lead
[framework] 2020-09-22 19:00:16,361 - org.apache.kafka.common.utils.AppInfoParser -331  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka version: 2.3.0
[framework] 2020-09-22 19:00:16,361 - org.apache.kafka.common.utils.AppInfoParser -331  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka commitId: fc1aaa116b661c8a
[framework] 2020-09-22 19:00:16,361 - org.apache.kafka.common.utils.AppInfoParser -331  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka startTimeMs: 1600772416361
[framework] 2020-09-22 19:00:16,361 - org.apache.kafka.clients.consumer.KafkaConsumer -331  [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=Commit2, groupId=DemoConsumer] Kafka consumer initialized
[framework] 2020-09-22 19:00:16,362 - org.apache.kafka.clients.consumer.KafkaConsumer -332  [main] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=Commit2, groupId=DemoConsumer] Subscribed to topic(s): Data
[framework] 2020-09-22 19:00:16,368 - cn.neyzoter.module.kafka.KafkaConsumerCliCommit -338  [KafkaConsumerExample_Commit2] INFO  cn.neyzoter.module.kafka.KafkaConsumerCliCommit  - [KafkaConsumerExample_Commit2]: Starting
[framework] 2020-09-22 19:00:16,370 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -340  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending FindCoordinator request to broker Kafka-1:9092 (id: -1 rack: null)
[framework] 2020-09-22 19:00:16,436 - org.apache.kafka.clients.NetworkClient -406  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Completed connection to node -1. Fetching API versions.
[framework] 2020-09-22 19:00:16,436 - org.apache.kafka.clients.NetworkClient -406  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating API versions fetch from node -1.
[framework] 2020-09-22 19:00:16,439 - org.apache.kafka.clients.NetworkClient -409  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=Commit2, groupId=DemoConsumer] Initiating connection to node Kafka-1:9092 (id: -1 rack: null) using address Kafka-1/47.110.251.155
[framework] 2020-09-22 19:00:16,443 - org.apache.kafka.common.metrics.Metrics -413  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-sent
[framework] 2020-09-22 19:00:16,444 - org.apache.kafka.common.metrics.Metrics -414  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-received
[framework] 2020-09-22 19:00:16,444 - org.apache.kafka.common.metrics.Metrics -414  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.latency
[framework] 2020-09-22 19:00:16,445 - org.apache.kafka.common.network.Selector -415  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=Commit2, groupId=DemoConsumer] Created socket with SO_RCVBUF = 65664, SO_SNDBUF = 131328, SO_TIMEOUT = 0 to node -1
[framework] 2020-09-22 19:00:16,445 - org.apache.kafka.clients.NetworkClient -415  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=Commit2, groupId=DemoConsumer] Completed connection to node -1. Fetching API versions.
[framework] 2020-09-22 19:00:16,445 - org.apache.kafka.clients.NetworkClient -415  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=Commit2, groupId=DemoConsumer] Initiating API versions fetch from node -1.
[framework] 2020-09-22 19:00:16,456 - org.apache.kafka.clients.NetworkClient -426  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-09-22 19:00:16,456 - org.apache.kafka.clients.NetworkClient -426  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=Commit2, groupId=DemoConsumer] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-09-22 19:00:16,458 - org.apache.kafka.clients.NetworkClient -428  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='Data')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node Kafka-1:9092 (id: -1 rack: null)
[framework] 2020-09-22 19:00:16,458 - org.apache.kafka.clients.NetworkClient -428  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='Data')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node Kafka-1:9092 (id: -1 rack: null)
[framework] 2020-09-22 19:00:16,480 - org.apache.kafka.clients.Metadata -450  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=Commit2, groupId=DemoConsumer] Updating last seen epoch from null to 0 for partition Data-0
[framework] 2020-09-22 19:00:16,480 - org.apache.kafka.clients.Metadata -450  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updating last seen epoch from null to 0 for partition Data-0
[framework] 2020-09-22 19:00:16,480 - org.apache.kafka.clients.Metadata -450  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=Commit2, groupId=DemoConsumer] Updating last seen epoch from null to 0 for partition Data-2
[framework] 2020-09-22 19:00:16,480 - org.apache.kafka.clients.Metadata -450  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updating last seen epoch from null to 0 for partition Data-2
[framework] 2020-09-22 19:00:16,481 - org.apache.kafka.clients.Metadata -451  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=Commit2, groupId=DemoConsumer] Updating last seen epoch from null to 0 for partition Data-1
[framework] 2020-09-22 19:00:16,481 - org.apache.kafka.clients.Metadata -451  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updating last seen epoch from null to 0 for partition Data-1
[framework] 2020-09-22 19:00:16,485 - org.apache.kafka.clients.Metadata -455  [KafkaConsumerExample_Commit2] INFO  org.apache.kafka.clients.Metadata  - [Consumer clientId=Commit2, groupId=DemoConsumer] Cluster ID: 8mkWuJWlQG-6kdWUyVTkZA
[framework] 2020-09-22 19:00:16,485 - org.apache.kafka.clients.Metadata -455  [kafka-producer-network-thread | DemoProducer] INFO  org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Cluster ID: 8mkWuJWlQG-6kdWUyVTkZA
[framework] 2020-09-22 19:00:16,486 - org.apache.kafka.clients.Metadata -456  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=Commit2, groupId=DemoConsumer] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = 8mkWuJWlQG-6kdWUyVTkZA, nodes = [Kafka-1:9092 (id: 1 rack: null)], partitions = [Partition(topic = Data, partition = 2, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = Data, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = Data, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])], controller = Kafka-1:9092 (id: 1 rack: null))}
[framework] 2020-09-22 19:00:16,486 - org.apache.kafka.clients.Metadata -456  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = 8mkWuJWlQG-6kdWUyVTkZA, nodes = [Kafka-1:9092 (id: 1 rack: null)], partitions = [Partition(topic = Data, partition = 2, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = Data, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = Data, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])], controller = Kafka-1:9092 (id: 1 rack: null))}
[framework] 2020-09-22 19:00:16,488 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -458  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Received FindCoordinator response ClientResponse(receivedTimeMs=1600772416487, latencyMs=51, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=2, clientId=Commit2, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=1, host='Kafka-1', port=9092))
[framework] 2020-09-22 19:00:16,488 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -458  [KafkaConsumerExample_Commit2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Discovered group coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-09-22 19:00:16,488 - org.apache.kafka.clients.NetworkClient -458  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=Commit2, groupId=DemoConsumer] Initiating connection to node Kafka-1:9092 (id: 2147483646 rack: null) using address Kafka-1/47.110.251.155
[framework] 2020-09-22 19:00:16,490 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -460  [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Heartbeat thread started
[framework] 2020-09-22 19:00:16,490 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -460  [KafkaConsumerExample_Commit2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Revoking previously assigned partitions []
[framework] 2020-09-22 19:00:16,490 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -460  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Disabling heartbeat thread
[framework] 2020-09-22 19:00:16,490 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -460  [KafkaConsumerExample_Commit2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] (Re-)joining group
[framework] 2020-09-22 19:00:16,491 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -461  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Joining group with current subscription: [Data]
[framework] 2020-09-22 19:00:16,493 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -463  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending JoinGroup (JoinGroupRequestData(groupId='DemoConsumer', sessionTimeoutMs=30000, rebalanceTimeoutMs=300000, memberId='', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 4, 68, 97, 116, 97, 0, 0, 0, 0])])) to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-09-22 19:00:16,494 - org.apache.kafka.common.metrics.Metrics -464  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2147483646.bytes-sent
[framework] 2020-09-22 19:00:16,496 - org.apache.kafka.common.metrics.Metrics -466  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2147483646.bytes-received
[framework] 2020-09-22 19:00:16,496 - org.apache.kafka.common.metrics.Metrics -466  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2147483646.latency
[framework] 2020-09-22 19:00:16,497 - org.apache.kafka.common.network.Selector -467  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=Commit2, groupId=DemoConsumer] Created socket with SO_RCVBUF = 65664, SO_SNDBUF = 131328, SO_TIMEOUT = 0 to node 2147483646
[framework] 2020-09-22 19:00:16,497 - org.apache.kafka.clients.NetworkClient -467  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=Commit2, groupId=DemoConsumer] Completed connection to node 2147483646. Fetching API versions.
[framework] 2020-09-22 19:00:16,497 - org.apache.kafka.clients.NetworkClient -467  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=Commit2, groupId=DemoConsumer] Initiating API versions fetch from node 2147483646.
[framework] 2020-09-22 19:00:16,502 - org.apache.kafka.clients.NetworkClient -472  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=Commit2, groupId=DemoConsumer] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-09-22 19:00:16,507 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -477  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Disabling heartbeat thread
[framework] 2020-09-22 19:00:16,507 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -477  [KafkaConsumerExample_Commit2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] (Re-)joining group
[framework] 2020-09-22 19:00:16,507 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -477  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Joining group with current subscription: [Data]
[framework] 2020-09-22 19:00:16,507 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -477  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending JoinGroup (JoinGroupRequestData(groupId='DemoConsumer', sessionTimeoutMs=30000, rebalanceTimeoutMs=300000, memberId='Commit2-405872a8-01ae-4255-beaf-d93d41972f75', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 4, 68, 97, 116, 97, 0, 0, 0, 0])])) to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-09-22 19:00:16,514 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -484  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Received successful JoinGroup response: JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=18, protocolName='range', leader='Commit2-405872a8-01ae-4255-beaf-d93d41972f75', memberId='Commit2-405872a8-01ae-4255-beaf-d93d41972f75', members=[JoinGroupResponseMember(memberId='Commit2-405872a8-01ae-4255-beaf-d93d41972f75', groupInstanceId='null', metadata=[0, 0, 0, 0, 0, 1, 0, 4, 68, 97, 116, 97, 0, 0, 0, 0])])
[framework] 2020-09-22 19:00:16,514 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -484  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Performing assignment using strategy range with subscriptions {Commit2-405872a8-01ae-4255-beaf-d93d41972f75=Subscription(topics=[Data])}
[framework] 2020-09-22 19:00:16,515 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -485  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Finished assignment for group: {Commit2-405872a8-01ae-4255-beaf-d93d41972f75=Assignment(partitions=[Data-0, Data-1, Data-2])}
[framework] 2020-09-22 19:00:16,516 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -486  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending leader SyncGroup to coordinator Kafka-1:9092 (id: 2147483646 rack: null): SyncGroupRequestData(groupId='DemoConsumer', generationId=18, memberId='Commit2-405872a8-01ae-4255-beaf-d93d41972f75', groupInstanceId='null', assignments=[SyncGroupRequestAssignment(memberId='Commit2-405872a8-01ae-4255-beaf-d93d41972f75', assignment=[0, 0, 0, 0, 0, 1, 0, 4, 68, 97, 116, 97, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0])])
[framework] 2020-09-22 19:00:16,524 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -494  [KafkaConsumerExample_Commit2] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Successfully joined group with generation 18
[framework] 2020-09-22 19:00:16,524 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -494  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Enabling heartbeat thread
[framework] 2020-09-22 19:00:16,531 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -501  [KafkaConsumerExample_Commit2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Setting newly assigned partitions: Data-2, Data-1, Data-0
[framework] 2020-09-22 19:00:16,547 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -517  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetching committed offsets for partitions: [Data-2, Data-1, Data-0]
[framework] 2020-09-22 19:00:16,555 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -525  [KafkaConsumerExample_Commit2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Setting offset for partition Data-2 to the committed offset FetchPosition{offset=3502, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}}
[framework] 2020-09-22 19:00:16,557 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -527  [KafkaConsumerExample_Commit2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Setting offset for partition Data-1 to the committed offset FetchPosition{offset=3683, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}}
[framework] 2020-09-22 19:00:16,557 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -527  [KafkaConsumerExample_Commit2] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Setting offset for partition Data-0 to the committed offset FetchPosition{offset=3694, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}}
[framework] 2020-09-22 19:00:16,562 - org.apache.kafka.clients.consumer.internals.Fetcher -532  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3502, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:16,562 - org.apache.kafka.clients.consumer.internals.Fetcher -532  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3683, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:16,562 - org.apache.kafka.clients.consumer.internals.Fetcher -532  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3694, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:16,562 - org.apache.kafka.clients.FetchSessionHandler -532  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 1 with 3 partition(s).
[framework] 2020-09-22 19:00:16,563 - org.apache.kafka.clients.consumer.internals.Fetcher -533  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED FullFetchRequest(Data-2, Data-1, Data-0) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:16,564 - org.apache.kafka.clients.NetworkClient -534  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=Commit2, groupId=DemoConsumer] Initiating connection to node Kafka-1:9092 (id: 1 rack: null) using address Kafka-1/47.110.251.155
[framework] 2020-09-22 19:00:16,568 - org.apache.kafka.common.metrics.Metrics -538  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-sent
[framework] 2020-09-22 19:00:16,569 - org.apache.kafka.common.metrics.Metrics -539  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-received
[framework] 2020-09-22 19:00:16,570 - org.apache.kafka.common.metrics.Metrics -540  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.latency
[framework] 2020-09-22 19:00:16,570 - org.apache.kafka.common.network.Selector -540  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=Commit2, groupId=DemoConsumer] Created socket with SO_RCVBUF = 65664, SO_SNDBUF = 131328, SO_TIMEOUT = 0 to node 1
[framework] 2020-09-22 19:00:16,570 - org.apache.kafka.clients.NetworkClient -540  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=Commit2, groupId=DemoConsumer] Completed connection to node 1. Fetching API versions.
[framework] 2020-09-22 19:00:16,570 - org.apache.kafka.clients.NetworkClient -540  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=Commit2, groupId=DemoConsumer] Initiating API versions fetch from node 1.
[framework] 2020-09-22 19:00:16,575 - org.apache.kafka.clients.NetworkClient -545  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=Commit2, groupId=DemoConsumer] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-09-22 19:00:16,588 - org.apache.kafka.clients.FetchSessionHandler -558  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent a full fetch response that created a new incremental fetch session 1886639015 with 3 response partition(s)
[framework] 2020-09-22 19:00:16,589 - org.apache.kafka.clients.consumer.internals.Fetcher -559  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3502 for partition Data-2 returned fetch data (error=NONE, highWaterMark=3547, lastStableOffset = 3547, logStartOffset = 2356, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=2619)
[framework] 2020-09-22 19:00:16,590 - org.apache.kafka.clients.consumer.internals.Fetcher -560  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3683 for partition Data-1 returned fetch data (error=NONE, highWaterMark=3730, lastStableOffset = 3730, logStartOffset = 2766, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=2724)
[framework] 2020-09-22 19:00:16,590 - org.apache.kafka.clients.consumer.internals.Fetcher -560  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3694 for partition Data-0 returned fetch data (error=NONE, highWaterMark=3741, lastStableOffset = 3741, logStartOffset = 2793, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=2723)
[framework] 2020-09-22 19:00:16,597 - org.apache.kafka.common.metrics.Metrics -567  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name Data-2.records-lag
[framework] 2020-09-22 19:00:16,598 - org.apache.kafka.common.metrics.Metrics -568  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name Data-2.records-lead
[framework] 2020-09-22 19:00:16,599 - org.apache.kafka.common.metrics.Metrics -569  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name Data-1.records-lag
[framework] 2020-09-22 19:00:16,600 - org.apache.kafka.common.metrics.Metrics -570  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name Data-1.records-lead
[framework] 2020-09-22 19:00:16,601 - org.apache.kafka.common.metrics.Metrics -571  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.Data.bytes-fetched
[framework] 2020-09-22 19:00:16,602 - org.apache.kafka.common.metrics.Metrics -572  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.Data.records-fetched
[framework] 2020-09-22 19:00:16,602 - org.apache.kafka.common.metrics.Metrics -572  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name Data-0.records-lag
[framework] 2020-09-22 19:00:16,603 - org.apache.kafka.common.metrics.Metrics -573  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name Data-0.records-lead
[framework] 2020-09-22 19:00:16,603 - org.apache.kafka.clients.consumer.internals.Fetcher -573  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3547, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:16,603 - org.apache.kafka.clients.consumer.internals.Fetcher -573  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3730, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:16,604 - org.apache.kafka.clients.consumer.internals.Fetcher -574  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3741, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:16,604 - org.apache.kafka.clients.FetchSessionHandler -574  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=1) for node 1. Added 0 partition(s), altered 3 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:16,604 - org.apache.kafka.clients.consumer.internals.Fetcher -574  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-2, Data-1, Data-0), toForget=(), implied=()) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,007 - org.apache.kafka.clients.NetworkClient -977  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating connection to node Kafka-1:9092 (id: 1 rack: null) using address Kafka-1/47.110.251.155
[framework] 2020-09-22 19:00:17,012 - org.apache.kafka.common.metrics.Metrics -982  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-sent
[framework] 2020-09-22 19:00:17,013 - org.apache.kafka.common.metrics.Metrics -983  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-received
[framework] 2020-09-22 19:00:17,013 - org.apache.kafka.common.metrics.Metrics -983  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.latency
[framework] 2020-09-22 19:00:17,014 - org.apache.kafka.common.network.Selector -984  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.network.Selector  - [Producer clientId=DemoProducer] Created socket with SO_RCVBUF = 32832, SO_SNDBUF = 131328, SO_TIMEOUT = 0 to node 1
[framework] 2020-09-22 19:00:17,014 - org.apache.kafka.clients.NetworkClient -984  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Completed connection to node 1. Fetching API versions.
[framework] 2020-09-22 19:00:17,014 - org.apache.kafka.clients.NetworkClient -984  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating API versions fetch from node 1.
[framework] 2020-09-22 19:00:17,018 - org.apache.kafka.clients.NetworkClient -988  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-09-22 19:00:17,019 - org.apache.kafka.common.metrics.Metrics -989  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.Data.records-per-batch
[framework] 2020-09-22 19:00:17,019 - org.apache.kafka.common.metrics.Metrics -989  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.Data.bytes
[framework] 2020-09-22 19:00:17,019 - org.apache.kafka.common.metrics.Metrics -989  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.Data.compression-rate
[framework] 2020-09-22 19:00:17,019 - org.apache.kafka.common.metrics.Metrics -989  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.Data.record-retries
[framework] 2020-09-22 19:00:17,019 - org.apache.kafka.common.metrics.Metrics -989  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.Data.record-errors
[framework] 2020-09-22 19:00:17,026 - org.apache.kafka.clients.FetchSessionHandler -996  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 1 response partition(s), 2 implied partition(s)
[framework] 2020-09-22 19:00:17,026 - org.apache.kafka.clients.consumer.internals.Fetcher -996  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3741 for partition Data-0 returned fetch data (error=NONE, highWaterMark=3742, lastStableOffset = 3742, logStartOffset = 2793, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=81)
[framework] 2020-09-22 19:00:17,027 - org.apache.kafka.clients.consumer.internals.Fetcher -997  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3547, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,027 - org.apache.kafka.clients.consumer.internals.Fetcher -997  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3730, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,027 - org.apache.kafka.clients.consumer.internals.Fetcher -997  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3742, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,028 - org.apache.kafka.clients.FetchSessionHandler -998  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=2) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:17,028 - org.apache.kafka.clients.consumer.internals.Fetcher -998  [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-0), toForget=(), implied=(Data-2, Data-1)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,033 - org.apache.kafka.clients.FetchSessionHandler -1003 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 2 response partition(s), 1 implied partition(s)
[framework] 2020-09-22 19:00:17,033 - org.apache.kafka.clients.consumer.internals.Fetcher -1003 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3547 for partition Data-2 returned fetch data (error=NONE, highWaterMark=3549, lastStableOffset = 3549, logStartOffset = 2356, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=102)
[framework] 2020-09-22 19:00:17,033 - org.apache.kafka.clients.consumer.internals.Fetcher -1003 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3730 for partition Data-1 returned fetch data (error=NONE, highWaterMark=3732, lastStableOffset = 3732, logStartOffset = 2766, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=102)
[framework] 2020-09-22 19:00:17,034 - org.apache.kafka.clients.consumer.internals.Fetcher -1004 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3742, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,034 - org.apache.kafka.clients.consumer.internals.Fetcher -1004 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3549, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,035 - org.apache.kafka.clients.consumer.internals.Fetcher -1005 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3732, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,035 - org.apache.kafka.clients.FetchSessionHandler -1005 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=3) for node 1. Added 0 partition(s), altered 2 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:17,035 - org.apache.kafka.clients.consumer.internals.Fetcher -1005 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-2, Data-1), toForget=(), implied=(Data-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,536 - org.apache.kafka.clients.FetchSessionHandler -1506 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 1 response partition(s), 2 implied partition(s)
[framework] 2020-09-22 19:00:17,537 - org.apache.kafka.clients.consumer.internals.Fetcher -1507 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3742 for partition Data-0 returned fetch data (error=NONE, highWaterMark=3744, lastStableOffset = 3744, logStartOffset = 2793, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=102)
[framework] 2020-09-22 19:00:17,538 - org.apache.kafka.clients.consumer.internals.Fetcher -1508 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3549, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,538 - org.apache.kafka.clients.consumer.internals.Fetcher -1508 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3732, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,538 - org.apache.kafka.clients.consumer.internals.Fetcher -1508 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3744, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,538 - org.apache.kafka.clients.FetchSessionHandler -1508 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=4) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:17,538 - org.apache.kafka.clients.consumer.internals.Fetcher -1508 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-0), toForget=(), implied=(Data-2, Data-1)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,544 - org.apache.kafka.clients.FetchSessionHandler -1514 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 2 response partition(s), 1 implied partition(s)
[framework] 2020-09-22 19:00:17,544 - org.apache.kafka.clients.consumer.internals.Fetcher -1514 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3549 for partition Data-2 returned fetch data (error=NONE, highWaterMark=3550, lastStableOffset = 3550, logStartOffset = 2356, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=81)
[framework] 2020-09-22 19:00:17,544 - org.apache.kafka.clients.consumer.internals.Fetcher -1514 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3732 for partition Data-1 returned fetch data (error=NONE, highWaterMark=3734, lastStableOffset = 3734, logStartOffset = 2766, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=103)
[framework] 2020-09-22 19:00:17,545 - org.apache.kafka.clients.consumer.internals.Fetcher -1515 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3744, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,545 - org.apache.kafka.clients.consumer.internals.Fetcher -1515 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3550, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,545 - org.apache.kafka.clients.consumer.internals.Fetcher -1515 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3734, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:17,545 - org.apache.kafka.clients.FetchSessionHandler -1515 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=5) for node 1. Added 0 partition(s), altered 2 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:17,545 - org.apache.kafka.clients.consumer.internals.Fetcher -1515 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-2, Data-1), toForget=(), implied=(Data-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,051 - org.apache.kafka.clients.FetchSessionHandler -2021 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 1 response partition(s), 2 implied partition(s)
[framework] 2020-09-22 19:00:18,051 - org.apache.kafka.clients.consumer.internals.Fetcher -2021 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3744 for partition Data-0 returned fetch data (error=NONE, highWaterMark=3746, lastStableOffset = 3746, logStartOffset = 2793, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=104)
[framework] 2020-09-22 19:00:18,054 - org.apache.kafka.clients.consumer.internals.Fetcher -2024 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3550, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,054 - org.apache.kafka.clients.consumer.internals.Fetcher -2024 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3734, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,055 - org.apache.kafka.clients.consumer.internals.Fetcher -2025 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3746, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,055 - org.apache.kafka.clients.FetchSessionHandler -2025 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=6) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:18,056 - org.apache.kafka.clients.consumer.internals.Fetcher -2026 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-0), toForget=(), implied=(Data-2, Data-1)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,062 - org.apache.kafka.clients.FetchSessionHandler -2032 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 2 response partition(s), 1 implied partition(s)
[framework] 2020-09-22 19:00:18,062 - org.apache.kafka.clients.consumer.internals.Fetcher -2032 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3550 for partition Data-2 returned fetch data (error=NONE, highWaterMark=3552, lastStableOffset = 3552, logStartOffset = 2356, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=104)
[framework] 2020-09-22 19:00:18,062 - org.apache.kafka.clients.consumer.internals.Fetcher -2032 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3734 for partition Data-1 returned fetch data (error=NONE, highWaterMark=3735, lastStableOffset = 3735, logStartOffset = 2766, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=82)
[framework] 2020-09-22 19:00:18,064 - org.apache.kafka.clients.consumer.internals.Fetcher -2034 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3746, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,064 - org.apache.kafka.clients.consumer.internals.Fetcher -2034 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3552, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,064 - org.apache.kafka.clients.consumer.internals.Fetcher -2034 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3735, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,064 - org.apache.kafka.clients.FetchSessionHandler -2034 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=7) for node 1. Added 0 partition(s), altered 2 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:18,065 - org.apache.kafka.clients.consumer.internals.Fetcher -2035 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-2, Data-1), toForget=(), implied=(Data-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,558 - org.apache.kafka.clients.FetchSessionHandler -2528 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 1 response partition(s), 2 implied partition(s)
[framework] 2020-09-22 19:00:18,559 - org.apache.kafka.clients.consumer.internals.Fetcher -2529 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3746 for partition Data-0 returned fetch data (error=NONE, highWaterMark=3747, lastStableOffset = 3747, logStartOffset = 2793, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=82)
[framework] 2020-09-22 19:00:18,559 - org.apache.kafka.clients.consumer.internals.Fetcher -2529 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3552, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,559 - org.apache.kafka.clients.consumer.internals.Fetcher -2529 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3735, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,559 - org.apache.kafka.clients.consumer.internals.Fetcher -2529 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3747, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,559 - org.apache.kafka.clients.FetchSessionHandler -2529 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=8) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:18,560 - org.apache.kafka.clients.consumer.internals.Fetcher -2530 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-0), toForget=(), implied=(Data-2, Data-1)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,565 - org.apache.kafka.clients.FetchSessionHandler -2535 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 2 response partition(s), 1 implied partition(s)
[framework] 2020-09-22 19:00:18,565 - org.apache.kafka.clients.consumer.internals.Fetcher -2535 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3552 for partition Data-2 returned fetch data (error=NONE, highWaterMark=3554, lastStableOffset = 3554, logStartOffset = 2356, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=104)
[framework] 2020-09-22 19:00:18,565 - org.apache.kafka.clients.consumer.internals.Fetcher -2535 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3735 for partition Data-1 returned fetch data (error=NONE, highWaterMark=3737, lastStableOffset = 3737, logStartOffset = 2766, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=104)
[framework] 2020-09-22 19:00:18,566 - org.apache.kafka.clients.consumer.internals.Fetcher -2536 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3747, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,566 - org.apache.kafka.clients.consumer.internals.Fetcher -2536 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3554, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,566 - org.apache.kafka.clients.consumer.internals.Fetcher -2536 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3737, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:18,566 - org.apache.kafka.clients.FetchSessionHandler -2536 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=9) for node 1. Added 0 partition(s), altered 2 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:18,566 - org.apache.kafka.clients.consumer.internals.Fetcher -2536 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-2, Data-1), toForget=(), implied=(Data-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,081 - org.apache.kafka.clients.FetchSessionHandler -3051 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 0 response partition(s), 3 implied partition(s)
[framework] 2020-09-22 19:00:19,082 - org.apache.kafka.clients.consumer.internals.Fetcher -3052 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3747, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,082 - org.apache.kafka.clients.consumer.internals.Fetcher -3052 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3554, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,082 - org.apache.kafka.clients.consumer.internals.Fetcher -3052 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3737, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,082 - org.apache.kafka.clients.FetchSessionHandler -3052 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=10) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:19,082 - org.apache.kafka.clients.consumer.internals.Fetcher -3052 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(Data-2, Data-1, Data-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,088 - org.apache.kafka.clients.FetchSessionHandler -3058 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 3 response partition(s)
[framework] 2020-09-22 19:00:19,088 - org.apache.kafka.clients.consumer.internals.Fetcher -3058 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3747 for partition Data-0 returned fetch data (error=NONE, highWaterMark=3749, lastStableOffset = 3749, logStartOffset = 2793, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=104)
[framework] 2020-09-22 19:00:19,089 - org.apache.kafka.clients.consumer.internals.Fetcher -3059 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3554 for partition Data-2 returned fetch data (error=NONE, highWaterMark=3555, lastStableOffset = 3555, logStartOffset = 2356, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=82)
[framework] 2020-09-22 19:00:19,089 - org.apache.kafka.clients.consumer.internals.Fetcher -3059 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3737 for partition Data-1 returned fetch data (error=NONE, highWaterMark=3739, lastStableOffset = 3739, logStartOffset = 2766, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=104)
[framework] 2020-09-22 19:00:19,089 - org.apache.kafka.clients.consumer.internals.Fetcher -3059 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3749, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,089 - org.apache.kafka.clients.consumer.internals.Fetcher -3059 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3555, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,089 - org.apache.kafka.clients.consumer.internals.Fetcher -3059 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3739, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,090 - org.apache.kafka.clients.FetchSessionHandler -3060 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=11) for node 1. Added 0 partition(s), altered 3 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:19,090 - org.apache.kafka.clients.consumer.internals.Fetcher -3060 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-2, Data-1, Data-0), toForget=(), implied=()) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,525 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -3495 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending Heartbeat request to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-09-22 19:00:19,537 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -3507 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=Commit2, groupId=DemoConsumer] Received successful Heartbeat response
[framework] 2020-09-22 19:00:19,595 - org.apache.kafka.clients.FetchSessionHandler -3565 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 0 response partition(s), 3 implied partition(s)
[framework] 2020-09-22 19:00:19,596 - org.apache.kafka.clients.consumer.internals.Fetcher -3566 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3749, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,596 - org.apache.kafka.clients.consumer.internals.Fetcher -3566 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3555, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,596 - org.apache.kafka.clients.consumer.internals.Fetcher -3566 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3739, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,596 - org.apache.kafka.clients.FetchSessionHandler -3566 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=12) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:19,596 - org.apache.kafka.clients.consumer.internals.Fetcher -3566 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(Data-2, Data-1, Data-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,605 - org.apache.kafka.clients.FetchSessionHandler -3575 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 3 response partition(s)
[framework] 2020-09-22 19:00:19,605 - org.apache.kafka.clients.consumer.internals.Fetcher -3575 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3749 for partition Data-0 returned fetch data (error=NONE, highWaterMark=3751, lastStableOffset = 3751, logStartOffset = 2793, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=104)
[framework] 2020-09-22 19:00:19,606 - org.apache.kafka.clients.consumer.internals.Fetcher -3576 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3555 for partition Data-2 returned fetch data (error=NONE, highWaterMark=3557, lastStableOffset = 3557, logStartOffset = 2356, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=104)
[framework] 2020-09-22 19:00:19,606 - org.apache.kafka.clients.consumer.internals.Fetcher -3576 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3739 for partition Data-1 returned fetch data (error=NONE, highWaterMark=3740, lastStableOffset = 3740, logStartOffset = 2766, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=82)
[framework] 2020-09-22 19:00:19,606 - org.apache.kafka.clients.consumer.internals.Fetcher -3576 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3751, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,606 - org.apache.kafka.clients.consumer.internals.Fetcher -3576 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3557, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,606 - org.apache.kafka.clients.consumer.internals.Fetcher -3576 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3740, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:19,607 - org.apache.kafka.clients.FetchSessionHandler -3577 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=13) for node 1. Added 0 partition(s), altered 3 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:19,607 - org.apache.kafka.clients.consumer.internals.Fetcher -3577 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-2, Data-1, Data-0), toForget=(), implied=()) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,116 - org.apache.kafka.clients.FetchSessionHandler -4086 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 0 response partition(s), 3 implied partition(s)
[framework] 2020-09-22 19:00:20,117 - org.apache.kafka.clients.consumer.internals.Fetcher -4087 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3751, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,117 - org.apache.kafka.clients.consumer.internals.Fetcher -4087 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3557, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,117 - org.apache.kafka.clients.consumer.internals.Fetcher -4087 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3740, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,117 - org.apache.kafka.clients.FetchSessionHandler -4087 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=14) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:20,117 - org.apache.kafka.clients.consumer.internals.Fetcher -4087 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(Data-2, Data-1, Data-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,126 - org.apache.kafka.clients.FetchSessionHandler -4096 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 3 response partition(s)
[framework] 2020-09-22 19:00:20,127 - org.apache.kafka.clients.consumer.internals.Fetcher -4097 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3751 for partition Data-0 returned fetch data (error=NONE, highWaterMark=3752, lastStableOffset = 3752, logStartOffset = 2793, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=82)
[framework] 2020-09-22 19:00:20,127 - org.apache.kafka.clients.consumer.internals.Fetcher -4097 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3557 for partition Data-2 returned fetch data (error=NONE, highWaterMark=3559, lastStableOffset = 3559, logStartOffset = 2356, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=104)
[framework] 2020-09-22 19:00:20,127 - org.apache.kafka.clients.consumer.internals.Fetcher -4097 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3740 for partition Data-1 returned fetch data (error=NONE, highWaterMark=3742, lastStableOffset = 3742, logStartOffset = 2766, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=104)
[framework] 2020-09-22 19:00:20,128 - org.apache.kafka.clients.consumer.internals.Fetcher -4098 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3752, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,128 - org.apache.kafka.clients.consumer.internals.Fetcher -4098 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3559, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,128 - org.apache.kafka.clients.consumer.internals.Fetcher -4098 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3742, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,128 - org.apache.kafka.clients.FetchSessionHandler -4098 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=15) for node 1. Added 0 partition(s), altered 3 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:20,128 - org.apache.kafka.clients.consumer.internals.Fetcher -4098 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-2, Data-1, Data-0), toForget=(), implied=()) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,624 - org.apache.kafka.clients.FetchSessionHandler -4594 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 1 response partition(s), 2 implied partition(s)
[framework] 2020-09-22 19:00:20,624 - org.apache.kafka.clients.consumer.internals.Fetcher -4594 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3752 for partition Data-0 returned fetch data (error=NONE, highWaterMark=3754, lastStableOffset = 3754, logStartOffset = 2793, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=104)
[framework] 2020-09-22 19:00:20,625 - org.apache.kafka.clients.consumer.internals.Fetcher -4595 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3559, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,625 - org.apache.kafka.clients.consumer.internals.Fetcher -4595 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3742, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,625 - org.apache.kafka.clients.consumer.internals.Fetcher -4595 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3754, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,625 - org.apache.kafka.clients.FetchSessionHandler -4595 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=16) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:20,625 - org.apache.kafka.clients.consumer.internals.Fetcher -4595 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-0), toForget=(), implied=(Data-2, Data-1)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,631 - org.apache.kafka.clients.FetchSessionHandler -4601 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1886639015 with 2 response partition(s), 1 implied partition(s)
[framework] 2020-09-22 19:00:20,631 - org.apache.kafka.clients.consumer.internals.Fetcher -4601 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3559 for partition Data-2 returned fetch data (error=NONE, highWaterMark=3560, lastStableOffset = 3560, logStartOffset = 2356, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=82)
[framework] 2020-09-22 19:00:20,631 - org.apache.kafka.clients.consumer.internals.Fetcher -4601 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3742 for partition Data-1 returned fetch data (error=NONE, highWaterMark=3744, lastStableOffset = 3744, logStartOffset = 2766, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=104)
[framework] 2020-09-22 19:00:20,632 - org.apache.kafka.clients.consumer.internals.Fetcher -4602 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-0 at position FetchPosition{offset=3754, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,632 - org.apache.kafka.clients.consumer.internals.Fetcher -4602 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-2 at position FetchPosition{offset=3560, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,632 - org.apache.kafka.clients.consumer.internals.Fetcher -4602 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition Data-1 at position FetchPosition{offset=3744, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-09-22 19:00:20,632 - org.apache.kafka.clients.FetchSessionHandler -4602 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=Commit2, groupId=DemoConsumer] Built incremental fetch (sessionId=1886639015, epoch=17) for node 1. Added 0 partition(s), altered 2 partition(s), removed 0 partition(s) out of 3 partition(s)
[framework] 2020-09-22 19:00:20,632 - org.apache.kafka.clients.consumer.internals.Fetcher -4602 [KafkaConsumerExample_Commit2] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=Commit2, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(Data-2, Data-1), toForget=(), implied=(Data-0)) to broker Kafka-1:9092 (id: 1 rack: null)
