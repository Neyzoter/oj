[framework] 2020-06-20 19:58:54,612 - org.apache.kafka.clients.producer.ProducerConfig -0    [main] INFO  org.apache.kafka.clients.producer.ProducerConfig  - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [kafka-1:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = DemoProducer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class cn.neyzoter.module.kafka.AllocationPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[framework] 2020-06-20 19:58:54,681 - org.apache.kafka.common.metrics.Metrics -69   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bufferpool-wait-time
[framework] 2020-06-20 19:58:54,686 - org.apache.kafka.common.metrics.Metrics -74   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name buffer-exhausted-records
[framework] 2020-06-20 19:58:54,691 - org.apache.kafka.common.metrics.Metrics -79   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name errors
[framework] 2020-06-20 19:58:54,698 - org.apache.kafka.common.metrics.Metrics -86   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name produce-throttle-time
[framework] 2020-06-20 19:58:54,707 - org.apache.kafka.common.metrics.Metrics -95   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-closed:
[framework] 2020-06-20 19:58:54,708 - org.apache.kafka.common.metrics.Metrics -96   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-created:
[framework] 2020-06-20 19:58:54,708 - org.apache.kafka.common.metrics.Metrics -96   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication:
[framework] 2020-06-20 19:58:54,708 - org.apache.kafka.common.metrics.Metrics -96   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-reauthentication:
[framework] 2020-06-20 19:58:54,709 - org.apache.kafka.common.metrics.Metrics -97   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication-no-reauth:
[framework] 2020-06-20 19:58:54,709 - org.apache.kafka.common.metrics.Metrics -97   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-authentication:
[framework] 2020-06-20 19:58:54,709 - org.apache.kafka.common.metrics.Metrics -97   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-reauthentication:
[framework] 2020-06-20 19:58:54,710 - org.apache.kafka.common.metrics.Metrics -98   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name reauthentication-latency:
[framework] 2020-06-20 19:58:54,710 - org.apache.kafka.common.metrics.Metrics -98   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent-received:
[framework] 2020-06-20 19:58:54,710 - org.apache.kafka.common.metrics.Metrics -98   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent:
[framework] 2020-06-20 19:58:54,711 - org.apache.kafka.common.metrics.Metrics -99   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-received:
[framework] 2020-06-20 19:58:54,711 - org.apache.kafka.common.metrics.Metrics -99   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name select-time:
[framework] 2020-06-20 19:58:54,712 - org.apache.kafka.common.metrics.Metrics -100  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name io-time:
[framework] 2020-06-20 19:58:54,759 - org.apache.kafka.common.metrics.Metrics -147  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name batch-size
[framework] 2020-06-20 19:58:54,759 - org.apache.kafka.common.metrics.Metrics -147  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name compression-rate
[framework] 2020-06-20 19:58:54,759 - org.apache.kafka.common.metrics.Metrics -147  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name queue-time
[framework] 2020-06-20 19:58:54,759 - org.apache.kafka.common.metrics.Metrics -147  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name request-time
[framework] 2020-06-20 19:58:54,759 - org.apache.kafka.common.metrics.Metrics -147  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-per-request
[framework] 2020-06-20 19:58:54,760 - org.apache.kafka.common.metrics.Metrics -148  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name record-retries
[framework] 2020-06-20 19:58:54,760 - org.apache.kafka.common.metrics.Metrics -148  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name record-size
[framework] 2020-06-20 19:58:54,764 - org.apache.kafka.common.metrics.Metrics -152  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name batch-split-rate
[framework] 2020-06-20 19:58:54,764 - org.apache.kafka.clients.producer.internals.Sender -152  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.producer.internals.Sender  - [Producer clientId=DemoProducer] Starting Kafka producer I/O thread.
[framework] 2020-06-20 19:58:54,767 - org.apache.kafka.common.utils.AppInfoParser -155  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka version: 2.3.0
[framework] 2020-06-20 19:58:54,767 - org.apache.kafka.common.utils.AppInfoParser -155  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka commitId: fc1aaa116b661c8a
[framework] 2020-06-20 19:58:54,767 - org.apache.kafka.common.utils.AppInfoParser -155  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka startTimeMs: 1592654334764
[framework] 2020-06-20 19:58:54,768 - org.apache.kafka.clients.producer.KafkaProducer -156  [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer  - [Producer clientId=DemoProducer] Kafka producer started
[framework] 2020-06-20 19:58:54,792 - org.apache.kafka.clients.NetworkClient -180  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initialize connection to node kafka-1:9092 (id: -1 rack: null) for sending metadata request
[framework] 2020-06-20 19:58:54,793 - org.apache.kafka.clients.NetworkClient -181  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating connection to node kafka-1:9092 (id: -1 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-20 19:58:54,812 - kafka.utils.Log4jControllerRegistration$ -200  [main] INFO  kafka.utils.Log4jControllerRegistration$  - Registered kafka:type=kafka.Log4jController MBean
[framework] 2020-06-20 19:58:54,820 - org.apache.kafka.clients.consumer.ConsumerConfig -208  [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig  - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [kafka-1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = consumer1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = DemoConsumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[framework] 2020-06-20 19:58:54,820 - org.apache.kafka.clients.consumer.KafkaConsumer -208  [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer1, groupId=DemoConsumer] Initializing the Kafka consumer
[framework] 2020-06-20 19:58:54,829 - org.apache.kafka.common.metrics.Metrics -217  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-throttle-time
[framework] 2020-06-20 19:58:54,830 - org.apache.kafka.common.metrics.Metrics -218  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-closed:
[framework] 2020-06-20 19:58:54,830 - org.apache.kafka.common.metrics.Metrics -218  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-created:
[framework] 2020-06-20 19:58:54,830 - org.apache.kafka.common.metrics.Metrics -218  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication:
[framework] 2020-06-20 19:58:54,830 - org.apache.kafka.common.metrics.Metrics -218  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-reauthentication:
[framework] 2020-06-20 19:58:54,830 - org.apache.kafka.common.metrics.Metrics -218  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication-no-reauth:
[framework] 2020-06-20 19:58:54,831 - org.apache.kafka.common.metrics.Metrics -219  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-authentication:
[framework] 2020-06-20 19:58:54,831 - org.apache.kafka.common.metrics.Metrics -219  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-reauthentication:
[framework] 2020-06-20 19:58:54,831 - org.apache.kafka.common.metrics.Metrics -219  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name reauthentication-latency:
[framework] 2020-06-20 19:58:54,832 - org.apache.kafka.common.metrics.Metrics -220  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent-received:
[framework] 2020-06-20 19:58:54,832 - org.apache.kafka.common.metrics.Metrics -220  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent:
[framework] 2020-06-20 19:58:54,833 - org.apache.kafka.common.metrics.Metrics -221  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-received:
[framework] 2020-06-20 19:58:54,833 - org.apache.kafka.common.metrics.Metrics -221  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name select-time:
[framework] 2020-06-20 19:58:54,834 - org.apache.kafka.common.metrics.Metrics -222  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name io-time:
[framework] 2020-06-20 19:58:54,850 - org.apache.kafka.common.metrics.Metrics -238  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name heartbeat-latency
[framework] 2020-06-20 19:58:54,850 - org.apache.kafka.common.metrics.Metrics -238  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name join-latency
[framework] 2020-06-20 19:58:54,851 - org.apache.kafka.common.metrics.Metrics -239  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name sync-latency
[framework] 2020-06-20 19:58:54,853 - org.apache.kafka.common.metrics.Metrics -241  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name commit-latency
[framework] 2020-06-20 19:58:54,856 - org.apache.kafka.common.metrics.Metrics -244  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-fetched
[framework] 2020-06-20 19:58:54,856 - org.apache.kafka.common.metrics.Metrics -244  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-fetched
[framework] 2020-06-20 19:58:54,857 - org.apache.kafka.common.metrics.Metrics -245  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-latency
[framework] 2020-06-20 19:58:54,857 - org.apache.kafka.common.metrics.Metrics -245  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lag
[framework] 2020-06-20 19:58:54,857 - org.apache.kafka.common.metrics.Metrics -245  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lead
[framework] 2020-06-20 19:58:54,859 - org.apache.kafka.common.utils.AppInfoParser -247  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka version: 2.3.0
[framework] 2020-06-20 19:58:54,860 - org.apache.kafka.common.utils.AppInfoParser -248  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka commitId: fc1aaa116b661c8a
[framework] 2020-06-20 19:58:54,860 - org.apache.kafka.common.utils.AppInfoParser -248  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka startTimeMs: 1592654334859
[framework] 2020-06-20 19:58:54,860 - org.apache.kafka.clients.consumer.KafkaConsumer -248  [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer1, groupId=DemoConsumer] Kafka consumer initialized
[framework] 2020-06-20 19:58:54,861 - org.apache.kafka.clients.consumer.ConsumerConfig -249  [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig  - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [kafka-1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = consumer2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = DemoConsumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[framework] 2020-06-20 19:58:54,861 - org.apache.kafka.clients.consumer.KafkaConsumer -249  [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer2, groupId=DemoConsumer] Initializing the Kafka consumer
[framework] 2020-06-20 19:58:54,862 - org.apache.kafka.common.metrics.Metrics -250  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-throttle-time
[framework] 2020-06-20 19:58:54,862 - org.apache.kafka.common.metrics.Metrics -250  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-closed:
[framework] 2020-06-20 19:58:54,862 - org.apache.kafka.common.metrics.Metrics -250  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-created:
[framework] 2020-06-20 19:58:54,863 - org.apache.kafka.common.metrics.Metrics -251  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication:
[framework] 2020-06-20 19:58:54,863 - org.apache.kafka.common.metrics.Metrics -251  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-reauthentication:
[framework] 2020-06-20 19:58:54,863 - org.apache.kafka.common.metrics.Metrics -251  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication-no-reauth:
[framework] 2020-06-20 19:58:54,864 - org.apache.kafka.common.metrics.Metrics -252  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-authentication:
[framework] 2020-06-20 19:58:54,864 - org.apache.kafka.common.metrics.Metrics -252  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-reauthentication:
[framework] 2020-06-20 19:58:54,864 - org.apache.kafka.common.metrics.Metrics -252  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name reauthentication-latency:
[framework] 2020-06-20 19:58:54,864 - org.apache.kafka.common.metrics.Metrics -252  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent-received:
[framework] 2020-06-20 19:58:54,865 - org.apache.kafka.common.metrics.Metrics -253  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent:
[framework] 2020-06-20 19:58:54,866 - org.apache.kafka.common.metrics.Metrics -254  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-received:
[framework] 2020-06-20 19:58:54,866 - org.apache.kafka.common.metrics.Metrics -254  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name select-time:
[framework] 2020-06-20 19:58:54,867 - org.apache.kafka.common.metrics.Metrics -255  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name io-time:
[framework] 2020-06-20 19:58:54,867 - cn.neyzoter.module.kafka.KafkaComsumerCli -255  [KafkaConsumerExample] INFO  cn.neyzoter.module.kafka.KafkaComsumerCli  - [KafkaConsumerExample]: Starting
[framework] 2020-06-20 19:58:54,867 - org.apache.kafka.common.metrics.Metrics -255  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name heartbeat-latency
[framework] 2020-06-20 19:58:54,868 - org.apache.kafka.clients.consumer.KafkaConsumer -256  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 19:58:54,868 - org.apache.kafka.common.metrics.Metrics -256  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name join-latency
[framework] 2020-06-20 19:58:54,868 - org.apache.kafka.common.metrics.Metrics -256  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name sync-latency
[framework] 2020-06-20 19:58:54,869 - org.apache.kafka.common.metrics.Metrics -257  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name commit-latency
[framework] 2020-06-20 19:58:54,869 - cn.neyzoter.module.kafka.KafkaComsumerCli -257  [KafkaConsumerExample] ERROR cn.neyzoter.module.kafka.KafkaComsumerCli  - [KafkaConsumerExample]: Error due to
java.util.MissingFormatArgumentException: Format specifier '%d'
	at java.util.Formatter.format(Formatter.java:2519)
	at java.util.Formatter.format(Formatter.java:2455)
	at java.lang.String.format(String.java:2940)
	at cn.neyzoter.module.kafka.KafkaComsumerCli.doWork(KafkaComsumerCli.java:43)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[framework] 2020-06-20 19:58:54,870 - org.apache.kafka.common.metrics.Metrics -258  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-fetched
[framework] 2020-06-20 19:58:54,871 - cn.neyzoter.module.kafka.KafkaComsumerCli -259  [KafkaConsumerExample] INFO  cn.neyzoter.module.kafka.KafkaComsumerCli  - [KafkaConsumerExample]: Stopped
[framework] 2020-06-20 19:58:54,871 - org.apache.kafka.common.metrics.Metrics -259  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-fetched
[framework] 2020-06-20 19:58:54,872 - org.apache.kafka.common.metrics.Metrics -260  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-latency
[framework] 2020-06-20 19:58:54,872 - org.apache.kafka.common.metrics.Metrics -260  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lag
[framework] 2020-06-20 19:58:54,872 - org.apache.kafka.common.metrics.Metrics -260  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lead
[framework] 2020-06-20 19:58:54,873 - org.apache.kafka.common.utils.AppInfoParser -261  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka version: 2.3.0
[framework] 2020-06-20 19:58:54,873 - org.apache.kafka.common.utils.AppInfoParser -261  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka commitId: fc1aaa116b661c8a
[framework] 2020-06-20 19:58:54,873 - org.apache.kafka.common.utils.AppInfoParser -261  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka startTimeMs: 1592654334872
[framework] 2020-06-20 19:58:54,873 - org.apache.kafka.clients.consumer.KafkaConsumer -261  [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer2, groupId=DemoConsumer] Kafka consumer initialized
[framework] 2020-06-20 19:58:54,873 - cn.neyzoter.module.kafka.KafkaComsumerCli -261  [KafkaConsumerExample] INFO  cn.neyzoter.module.kafka.KafkaComsumerCli  - [KafkaConsumerExample]: Starting
[framework] 2020-06-20 19:58:54,874 - org.apache.kafka.clients.consumer.KafkaConsumer -262  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer2, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 19:58:54,874 - cn.neyzoter.module.kafka.KafkaComsumerCli -262  [KafkaConsumerExample] ERROR cn.neyzoter.module.kafka.KafkaComsumerCli  - [KafkaConsumerExample]: Error due to
java.util.MissingFormatArgumentException: Format specifier '%d'
	at java.util.Formatter.format(Formatter.java:2519)
	at java.util.Formatter.format(Formatter.java:2455)
	at java.lang.String.format(String.java:2940)
	at cn.neyzoter.module.kafka.KafkaComsumerCli.doWork(KafkaComsumerCli.java:43)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
[framework] 2020-06-20 19:58:54,874 - cn.neyzoter.module.kafka.KafkaComsumerCli -262  [KafkaConsumerExample] INFO  cn.neyzoter.module.kafka.KafkaComsumerCli  - [KafkaConsumerExample]: Stopped
[framework] 2020-06-20 19:58:54,904 - org.apache.kafka.common.metrics.Metrics -292  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-sent
[framework] 2020-06-20 19:58:54,905 - org.apache.kafka.common.metrics.Metrics -293  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-received
[framework] 2020-06-20 19:58:54,905 - org.apache.kafka.common.metrics.Metrics -293  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.latency
[framework] 2020-06-20 19:58:54,906 - org.apache.kafka.common.network.Selector -294  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.network.Selector  - [Producer clientId=DemoProducer] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
[framework] 2020-06-20 19:58:55,034 - org.apache.kafka.clients.NetworkClient -422  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Completed connection to node -1. Fetching API versions.
[framework] 2020-06-20 19:58:55,034 - org.apache.kafka.clients.NetworkClient -422  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating API versions fetch from node -1.
[framework] 2020-06-20 19:58:55,046 - org.apache.kafka.clients.NetworkClient -434  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-20 19:58:55,047 - org.apache.kafka.clients.NetworkClient -435  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Sending metadata request MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node kafka-1:9092 (id: -1 rack: null)
[framework] 2020-06-20 19:58:55,064 - org.apache.kafka.clients.Metadata -452  [kafka-producer-network-thread | DemoProducer] INFO  org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Cluster ID: MT1saCQCQj6WuKonjf5obA
[framework] 2020-06-20 19:58:55,064 - org.apache.kafka.clients.Metadata -452  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = MT1saCQCQj6WuKonjf5obA, nodes = [Kafka-1:9093 (id: 2 rack: null), Kafka-1:9092 (id: 1 rack: null)], partitions = [], controller = Kafka-1:9092 (id: 1 rack: null))}
[framework] 2020-06-20 19:58:55,771 - org.apache.kafka.clients.NetworkClient -1159 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initialize connection to node Kafka-1:9093 (id: 2 rack: null) for sending metadata request
[framework] 2020-06-20 19:58:55,772 - org.apache.kafka.clients.NetworkClient -1160 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating connection to node Kafka-1:9093 (id: 2 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-20 19:58:55,775 - org.apache.kafka.common.metrics.Metrics -1163 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2.bytes-sent
[framework] 2020-06-20 19:58:55,776 - org.apache.kafka.common.metrics.Metrics -1164 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2.bytes-received
[framework] 2020-06-20 19:58:55,777 - org.apache.kafka.common.metrics.Metrics -1165 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2.latency
[framework] 2020-06-20 19:58:55,777 - org.apache.kafka.common.network.Selector -1165 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.network.Selector  - [Producer clientId=DemoProducer] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2
[framework] 2020-06-20 19:58:55,777 - org.apache.kafka.clients.NetworkClient -1165 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Completed connection to node 2. Fetching API versions.
[framework] 2020-06-20 19:58:55,777 - org.apache.kafka.clients.NetworkClient -1165 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating API versions fetch from node 2.
[framework] 2020-06-20 19:58:55,781 - org.apache.kafka.clients.NetworkClient -1169 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Recorded API versions for node 2: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-20 19:58:55,782 - org.apache.kafka.clients.NetworkClient -1170 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='topic1')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node Kafka-1:9093 (id: 2 rack: null)
[framework] 2020-06-20 19:58:55,794 - org.apache.kafka.clients.Metadata -1182 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updating last seen epoch from null to 0 for partition topic1-0
[framework] 2020-06-20 19:58:55,794 - org.apache.kafka.clients.Metadata -1182 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updating last seen epoch from null to 0 for partition topic1-2
[framework] 2020-06-20 19:58:55,794 - org.apache.kafka.clients.Metadata -1182 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updating last seen epoch from null to 0 for partition topic1-1
[framework] 2020-06-20 19:58:55,797 - org.apache.kafka.clients.Metadata -1185 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updated cluster metadata updateVersion 3 to MetadataCache{cluster=Cluster(id = MT1saCQCQj6WuKonjf5obA, nodes = [Kafka-1:9093 (id: 2 rack: null), Kafka-1:9092 (id: 1 rack: null)], partitions = [Partition(topic = topic1, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = topic1, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = topic1, partition = 2, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])], controller = Kafka-1:9092 (id: 1 rack: null))}
[framework] 2020-06-20 19:58:55,809 - org.apache.kafka.clients.NetworkClient -1197 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating connection to node Kafka-1:9092 (id: 1 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-20 19:58:55,812 - org.apache.kafka.common.metrics.Metrics -1200 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-sent
[framework] 2020-06-20 19:58:55,813 - org.apache.kafka.common.metrics.Metrics -1201 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-received
[framework] 2020-06-20 19:58:55,813 - org.apache.kafka.common.metrics.Metrics -1201 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.latency
[framework] 2020-06-20 19:58:55,813 - org.apache.kafka.common.network.Selector -1201 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.network.Selector  - [Producer clientId=DemoProducer] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 1
[framework] 2020-06-20 19:58:55,813 - org.apache.kafka.clients.NetworkClient -1201 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Completed connection to node 1. Fetching API versions.
[framework] 2020-06-20 19:58:55,813 - org.apache.kafka.clients.NetworkClient -1201 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating API versions fetch from node 1.
[framework] 2020-06-20 19:58:55,817 - org.apache.kafka.clients.NetworkClient -1205 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-20 19:58:55,820 - org.apache.kafka.common.metrics.Metrics -1208 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.records-per-batch
[framework] 2020-06-20 19:58:55,820 - org.apache.kafka.common.metrics.Metrics -1208 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.bytes
[framework] 2020-06-20 19:58:55,820 - org.apache.kafka.common.metrics.Metrics -1208 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.compression-rate
[framework] 2020-06-20 19:58:55,820 - org.apache.kafka.common.metrics.Metrics -1208 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.record-retries
[framework] 2020-06-20 19:58:55,821 - org.apache.kafka.common.metrics.Metrics -1209 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.record-errors
