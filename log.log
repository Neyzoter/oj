[framework] 2020-06-20 18:14:57,099 - org.apache.kafka.clients.producer.ProducerConfig -0    [main] INFO  org.apache.kafka.clients.producer.ProducerConfig  - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [kafka-1:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = DemoProducer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[framework] 2020-06-20 18:14:57,171 - org.apache.kafka.common.metrics.Metrics -72   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bufferpool-wait-time
[framework] 2020-06-20 18:14:57,175 - org.apache.kafka.common.metrics.Metrics -76   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name buffer-exhausted-records
[framework] 2020-06-20 18:14:57,180 - org.apache.kafka.common.metrics.Metrics -81   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name errors
[framework] 2020-06-20 18:14:57,187 - org.apache.kafka.common.metrics.Metrics -88   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name produce-throttle-time
[framework] 2020-06-20 18:14:57,198 - org.apache.kafka.common.metrics.Metrics -99   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-closed:
[framework] 2020-06-20 18:14:57,198 - org.apache.kafka.common.metrics.Metrics -99   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-created:
[framework] 2020-06-20 18:14:57,199 - org.apache.kafka.common.metrics.Metrics -100  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication:
[framework] 2020-06-20 18:14:57,199 - org.apache.kafka.common.metrics.Metrics -100  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-reauthentication:
[framework] 2020-06-20 18:14:57,199 - org.apache.kafka.common.metrics.Metrics -100  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication-no-reauth:
[framework] 2020-06-20 18:14:57,200 - org.apache.kafka.common.metrics.Metrics -101  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-authentication:
[framework] 2020-06-20 18:14:57,200 - org.apache.kafka.common.metrics.Metrics -101  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-reauthentication:
[framework] 2020-06-20 18:14:57,200 - org.apache.kafka.common.metrics.Metrics -101  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name reauthentication-latency:
[framework] 2020-06-20 18:14:57,201 - org.apache.kafka.common.metrics.Metrics -102  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent-received:
[framework] 2020-06-20 18:14:57,201 - org.apache.kafka.common.metrics.Metrics -102  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent:
[framework] 2020-06-20 18:14:57,202 - org.apache.kafka.common.metrics.Metrics -103  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-received:
[framework] 2020-06-20 18:14:57,202 - org.apache.kafka.common.metrics.Metrics -103  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name select-time:
[framework] 2020-06-20 18:14:57,203 - org.apache.kafka.common.metrics.Metrics -104  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name io-time:
[framework] 2020-06-20 18:14:57,253 - org.apache.kafka.common.metrics.Metrics -154  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name batch-size
[framework] 2020-06-20 18:14:57,253 - org.apache.kafka.common.metrics.Metrics -154  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name compression-rate
[framework] 2020-06-20 18:14:57,253 - org.apache.kafka.common.metrics.Metrics -154  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name queue-time
[framework] 2020-06-20 18:14:57,253 - org.apache.kafka.common.metrics.Metrics -154  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name request-time
[framework] 2020-06-20 18:14:57,254 - org.apache.kafka.common.metrics.Metrics -155  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-per-request
[framework] 2020-06-20 18:14:57,254 - org.apache.kafka.common.metrics.Metrics -155  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name record-retries
[framework] 2020-06-20 18:14:57,254 - org.apache.kafka.common.metrics.Metrics -155  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name record-size
[framework] 2020-06-20 18:14:57,258 - org.apache.kafka.common.metrics.Metrics -159  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name batch-split-rate
[framework] 2020-06-20 18:14:57,259 - org.apache.kafka.clients.producer.internals.Sender -160  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.producer.internals.Sender  - [Producer clientId=DemoProducer] Starting Kafka producer I/O thread.
[framework] 2020-06-20 18:14:57,261 - org.apache.kafka.common.utils.AppInfoParser -162  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka version: 2.3.0
[framework] 2020-06-20 18:14:57,261 - org.apache.kafka.common.utils.AppInfoParser -162  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka commitId: fc1aaa116b661c8a
[framework] 2020-06-20 18:14:57,261 - org.apache.kafka.common.utils.AppInfoParser -162  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka startTimeMs: 1592648097258
[framework] 2020-06-20 18:14:57,263 - org.apache.kafka.clients.producer.KafkaProducer -164  [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer  - [Producer clientId=DemoProducer] Kafka producer started
[framework] 2020-06-20 18:14:57,270 - org.apache.kafka.clients.NetworkClient -171  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initialize connection to node kafka-1:9092 (id: -1 rack: null) for sending metadata request
[framework] 2020-06-20 18:14:57,271 - org.apache.kafka.clients.NetworkClient -172  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating connection to node kafka-1:9092 (id: -1 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-20 18:14:57,308 - kafka.utils.Log4jControllerRegistration$ -209  [main] INFO  kafka.utils.Log4jControllerRegistration$  - Registered kafka:type=kafka.Log4jController MBean
[framework] 2020-06-20 18:14:57,315 - org.apache.kafka.clients.consumer.ConsumerConfig -216  [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig  - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [kafka-1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = DemoConsumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[framework] 2020-06-20 18:14:57,315 - org.apache.kafka.clients.consumer.KafkaConsumer -216  [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Initializing the Kafka consumer
[framework] 2020-06-20 18:14:57,325 - org.apache.kafka.common.metrics.Metrics -226  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-throttle-time
[framework] 2020-06-20 18:14:57,325 - org.apache.kafka.common.metrics.Metrics -226  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-closed:
[framework] 2020-06-20 18:14:57,325 - org.apache.kafka.common.metrics.Metrics -226  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-created:
[framework] 2020-06-20 18:14:57,326 - org.apache.kafka.common.metrics.Metrics -227  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication:
[framework] 2020-06-20 18:14:57,326 - org.apache.kafka.common.metrics.Metrics -227  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-reauthentication:
[framework] 2020-06-20 18:14:57,326 - org.apache.kafka.common.metrics.Metrics -227  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication-no-reauth:
[framework] 2020-06-20 18:14:57,326 - org.apache.kafka.common.metrics.Metrics -227  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-authentication:
[framework] 2020-06-20 18:14:57,327 - org.apache.kafka.common.metrics.Metrics -228  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-reauthentication:
[framework] 2020-06-20 18:14:57,327 - org.apache.kafka.common.metrics.Metrics -228  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name reauthentication-latency:
[framework] 2020-06-20 18:14:57,327 - org.apache.kafka.common.metrics.Metrics -228  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent-received:
[framework] 2020-06-20 18:14:57,327 - org.apache.kafka.common.metrics.Metrics -228  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent:
[framework] 2020-06-20 18:14:57,328 - org.apache.kafka.common.metrics.Metrics -229  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-received:
[framework] 2020-06-20 18:14:57,328 - org.apache.kafka.common.metrics.Metrics -229  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name select-time:
[framework] 2020-06-20 18:14:57,329 - org.apache.kafka.common.metrics.Metrics -230  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name io-time:
[framework] 2020-06-20 18:14:57,340 - org.apache.kafka.common.metrics.Metrics -241  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name heartbeat-latency
[framework] 2020-06-20 18:14:57,340 - org.apache.kafka.common.metrics.Metrics -241  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name join-latency
[framework] 2020-06-20 18:14:57,341 - org.apache.kafka.common.metrics.Metrics -242  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name sync-latency
[framework] 2020-06-20 18:14:57,343 - org.apache.kafka.common.metrics.Metrics -244  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name commit-latency
[framework] 2020-06-20 18:14:57,345 - org.apache.kafka.common.metrics.Metrics -246  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-fetched
[framework] 2020-06-20 18:14:57,345 - org.apache.kafka.common.metrics.Metrics -246  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-fetched
[framework] 2020-06-20 18:14:57,345 - org.apache.kafka.common.metrics.Metrics -246  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-latency
[framework] 2020-06-20 18:14:57,346 - org.apache.kafka.common.metrics.Metrics -247  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lag
[framework] 2020-06-20 18:14:57,346 - org.apache.kafka.common.metrics.Metrics -247  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lead
[framework] 2020-06-20 18:14:57,348 - org.apache.kafka.common.utils.AppInfoParser -249  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka version: 2.3.0
[framework] 2020-06-20 18:14:57,348 - org.apache.kafka.common.utils.AppInfoParser -249  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka commitId: fc1aaa116b661c8a
[framework] 2020-06-20 18:14:57,348 - org.apache.kafka.common.utils.AppInfoParser -249  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka startTimeMs: 1592648097348
[framework] 2020-06-20 18:14:57,348 - org.apache.kafka.clients.consumer.KafkaConsumer -249  [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Kafka consumer initialized
[framework] 2020-06-20 18:14:57,355 - cn.neyzoter.module.kafka.KafkaComsumerCli -256  [KafkaConsumerExample] INFO  cn.neyzoter.module.kafka.KafkaComsumerCli  - [KafkaConsumerExample]: Starting
[framework] 2020-06-20 18:14:57,356 - org.apache.kafka.clients.consumer.KafkaConsumer -257  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:57,357 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -258  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending FindCoordinator request to broker kafka-1:9092 (id: -1 rack: null)
[framework] 2020-06-20 18:14:57,379 - org.apache.kafka.common.metrics.Metrics -280  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-sent
[framework] 2020-06-20 18:14:57,380 - org.apache.kafka.common.metrics.Metrics -281  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-received
[framework] 2020-06-20 18:14:57,381 - org.apache.kafka.common.metrics.Metrics -282  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.latency
[framework] 2020-06-20 18:14:57,381 - org.apache.kafka.common.network.Selector -282  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.network.Selector  - [Producer clientId=DemoProducer] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
[framework] 2020-06-20 18:14:57,480 - org.apache.kafka.clients.NetworkClient -381  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Completed connection to node -1. Fetching API versions.
[framework] 2020-06-20 18:14:57,480 - org.apache.kafka.clients.NetworkClient -381  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating API versions fetch from node -1.
[framework] 2020-06-20 18:14:57,481 - org.apache.kafka.clients.NetworkClient -382  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Initiating connection to node kafka-1:9092 (id: -1 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-20 18:14:57,486 - org.apache.kafka.common.metrics.Metrics -387  [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-sent
[framework] 2020-06-20 18:14:57,486 - org.apache.kafka.common.metrics.Metrics -387  [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-received
[framework] 2020-06-20 18:14:57,487 - org.apache.kafka.common.metrics.Metrics -388  [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.latency
[framework] 2020-06-20 18:14:57,487 - org.apache.kafka.common.network.Selector -388  [KafkaConsumerExample] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
[framework] 2020-06-20 18:14:57,487 - org.apache.kafka.clients.NetworkClient -388  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed connection to node -1. Fetching API versions.
[framework] 2020-06-20 18:14:57,487 - org.apache.kafka.clients.NetworkClient -388  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Initiating API versions fetch from node -1.
[framework] 2020-06-20 18:14:57,495 - org.apache.kafka.clients.NetworkClient -396  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-20 18:14:57,495 - org.apache.kafka.clients.NetworkClient -396  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-20 18:14:57,496 - org.apache.kafka.clients.NetworkClient -397  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='topic1')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node kafka-1:9092 (id: -1 rack: null)
[framework] 2020-06-20 18:14:57,496 - org.apache.kafka.clients.NetworkClient -397  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='topic1')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node kafka-1:9092 (id: -1 rack: null)
[framework] 2020-06-20 18:14:57,525 - org.apache.kafka.clients.NetworkClient -426  [KafkaConsumerExample] WARN  org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Error while fetching metadata with correlation id 2 : {topic1=LEADER_NOT_AVAILABLE}
[framework] 2020-06-20 18:14:57,527 - org.apache.kafka.clients.NetworkClient -428  [kafka-producer-network-thread | DemoProducer] WARN  org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Error while fetching metadata with correlation id 1 : {topic1=LEADER_NOT_AVAILABLE}
[framework] 2020-06-20 18:14:57,528 - org.apache.kafka.clients.Metadata -429  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Requesting metadata update for topic topic1 due to error LEADER_NOT_AVAILABLE
[framework] 2020-06-20 18:14:57,528 - org.apache.kafka.clients.Metadata -429  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Requesting metadata update for topic topic1 due to error LEADER_NOT_AVAILABLE
[framework] 2020-06-20 18:14:57,530 - org.apache.kafka.clients.Metadata -431  [KafkaConsumerExample] INFO  org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Cluster ID: MT1saCQCQj6WuKonjf5obA
[framework] 2020-06-20 18:14:57,530 - org.apache.kafka.clients.Metadata -431  [kafka-producer-network-thread | DemoProducer] INFO  org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Cluster ID: MT1saCQCQj6WuKonjf5obA
[framework] 2020-06-20 18:14:57,530 - org.apache.kafka.clients.Metadata -431  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = MT1saCQCQj6WuKonjf5obA, nodes = [Kafka-1:9092 (id: 1 rack: null)], partitions = [], controller = Kafka-1:9092 (id: 1 rack: null))}
[framework] 2020-06-20 18:14:57,530 - org.apache.kafka.clients.Metadata -431  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = MT1saCQCQj6WuKonjf5obA, nodes = [Kafka-1:9092 (id: 1 rack: null)], partitions = [], controller = Kafka-1:9092 (id: 1 rack: null))}
[framework] 2020-06-20 18:14:57,531 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -432  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Received FindCoordinator response ClientResponse(receivedTimeMs=1592648097530, latencyMs=50, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=2, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=1, host='Kafka-1', port=9092))
[framework] 2020-06-20 18:14:57,531 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -432  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Discovered group coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-20 18:14:57,531 - org.apache.kafka.clients.NetworkClient -432  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Initiating connection to node Kafka-1:9092 (id: 2147483646 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-20 18:14:57,533 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -434  [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Heartbeat thread started
[framework] 2020-06-20 18:14:57,534 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -435  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending synchronous auto-commit of offsets {}
[framework] 2020-06-20 18:14:57,534 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -435  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Revoking previously assigned partitions []
[framework] 2020-06-20 18:14:57,534 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -435  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Disabling heartbeat thread
[framework] 2020-06-20 18:14:57,534 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -435  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] (Re-)joining group
[framework] 2020-06-20 18:14:57,534 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -435  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Joining group with current subscription: [topic1]
[framework] 2020-06-20 18:14:57,537 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -438  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending JoinGroup (JoinGroupRequestData(groupId='DemoConsumer', sessionTimeoutMs=30000, rebalanceTimeoutMs=300000, memberId='', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 116, 111, 112, 105, 99, 49, 0, 0, 0, 0])])) to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-20 18:14:57,555 - org.apache.kafka.common.metrics.Metrics -456  [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2147483646.bytes-sent
[framework] 2020-06-20 18:14:57,556 - org.apache.kafka.common.metrics.Metrics -457  [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2147483646.bytes-received
[framework] 2020-06-20 18:14:57,557 - org.apache.kafka.common.metrics.Metrics -458  [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2147483646.latency
[framework] 2020-06-20 18:14:57,557 - org.apache.kafka.common.network.Selector -458  [KafkaConsumerExample] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483646
[framework] 2020-06-20 18:14:57,557 - org.apache.kafka.clients.NetworkClient -458  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed connection to node 2147483646. Fetching API versions.
[framework] 2020-06-20 18:14:57,557 - org.apache.kafka.clients.NetworkClient -458  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Initiating API versions fetch from node 2147483646.
[framework] 2020-06-20 18:14:57,618 - org.apache.kafka.clients.NetworkClient -519  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Initialize connection to node Kafka-1:9092 (id: 1 rack: null) for sending metadata request
[framework] 2020-06-20 18:14:57,618 - org.apache.kafka.clients.NetworkClient -519  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Initiating connection to node Kafka-1:9092 (id: 1 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-20 18:14:57,628 - org.apache.kafka.clients.NetworkClient -529  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initialize connection to node Kafka-1:9092 (id: 1 rack: null) for sending metadata request
[framework] 2020-06-20 18:14:57,628 - org.apache.kafka.clients.NetworkClient -529  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating connection to node Kafka-1:9092 (id: 1 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-20 18:14:57,672 - org.apache.kafka.common.metrics.Metrics -573  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-sent
[framework] 2020-06-20 18:14:57,672 - org.apache.kafka.clients.NetworkClient -573  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-20 18:14:57,672 - org.apache.kafka.common.metrics.Metrics -573  [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-sent
[framework] 2020-06-20 18:14:57,673 - org.apache.kafka.common.metrics.Metrics -574  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-received
[framework] 2020-06-20 18:14:57,673 - org.apache.kafka.common.metrics.Metrics -574  [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-received
[framework] 2020-06-20 18:14:57,673 - org.apache.kafka.common.metrics.Metrics -574  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.latency
[framework] 2020-06-20 18:14:57,673 - org.apache.kafka.common.metrics.Metrics -574  [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.latency
[framework] 2020-06-20 18:14:57,674 - org.apache.kafka.common.network.Selector -575  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.network.Selector  - [Producer clientId=DemoProducer] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 1
[framework] 2020-06-20 18:14:57,674 - org.apache.kafka.common.network.Selector -575  [KafkaConsumerExample] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 1
[framework] 2020-06-20 18:14:57,674 - org.apache.kafka.clients.NetworkClient -575  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Completed connection to node 1. Fetching API versions.
[framework] 2020-06-20 18:14:57,674 - org.apache.kafka.clients.NetworkClient -575  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed connection to node 1. Fetching API versions.
[framework] 2020-06-20 18:14:57,674 - org.apache.kafka.clients.NetworkClient -575  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating API versions fetch from node 1.
[framework] 2020-06-20 18:14:57,674 - org.apache.kafka.clients.NetworkClient -575  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Initiating API versions fetch from node 1.
[framework] 2020-06-20 18:14:57,681 - org.apache.kafka.clients.NetworkClient -582  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-20 18:14:57,681 - org.apache.kafka.clients.NetworkClient -582  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-20 18:14:57,681 - org.apache.kafka.clients.NetworkClient -582  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='topic1')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:57,681 - org.apache.kafka.clients.NetworkClient -582  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='topic1')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:57,691 - org.apache.kafka.clients.Metadata -592  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updating last seen epoch from null to 0 for partition topic1-0
[framework] 2020-06-20 18:14:57,691 - org.apache.kafka.clients.Metadata -592  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Updating last seen epoch from null to 0 for partition topic1-0
[framework] 2020-06-20 18:14:57,691 - org.apache.kafka.clients.Metadata -592  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Updating last seen epoch from null to 0 for partition topic1-2
[framework] 2020-06-20 18:14:57,691 - org.apache.kafka.clients.Metadata -592  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updating last seen epoch from null to 0 for partition topic1-2
[framework] 2020-06-20 18:14:57,691 - org.apache.kafka.clients.Metadata -592  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Updating last seen epoch from null to 0 for partition topic1-1
[framework] 2020-06-20 18:14:57,691 - org.apache.kafka.clients.Metadata -592  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updating last seen epoch from null to 0 for partition topic1-1
[framework] 2020-06-20 18:14:57,694 - org.apache.kafka.clients.Metadata -595  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Updated cluster metadata updateVersion 3 to MetadataCache{cluster=Cluster(id = MT1saCQCQj6WuKonjf5obA, nodes = [Kafka-1:9092 (id: 1 rack: null)], partitions = [Partition(topic = topic1, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = topic1, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = topic1, partition = 2, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])], controller = Kafka-1:9092 (id: 1 rack: null))}
[framework] 2020-06-20 18:14:57,694 - org.apache.kafka.clients.Metadata -595  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updated cluster metadata updateVersion 3 to MetadataCache{cluster=Cluster(id = MT1saCQCQj6WuKonjf5obA, nodes = [Kafka-1:9092 (id: 1 rack: null)], partitions = [Partition(topic = topic1, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = topic1, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = topic1, partition = 2, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])], controller = Kafka-1:9092 (id: 1 rack: null))}
[framework] 2020-06-20 18:14:57,695 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -596  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Disabling heartbeat thread
[framework] 2020-06-20 18:14:57,695 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -596  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] (Re-)joining group
[framework] 2020-06-20 18:14:57,695 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -596  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Joining group with current subscription: [topic1]
[framework] 2020-06-20 18:14:57,695 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -596  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending JoinGroup (JoinGroupRequestData(groupId='DemoConsumer', sessionTimeoutMs=30000, rebalanceTimeoutMs=300000, memberId='consumer-1-ab505c32-77e9-4574-a521-d487888e4fcf', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 116, 111, 112, 105, 99, 49, 0, 0, 0, 0])])) to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-20 18:14:57,709 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -610  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Received successful JoinGroup response: JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=1, protocolName='range', leader='consumer-1-ab505c32-77e9-4574-a521-d487888e4fcf', memberId='consumer-1-ab505c32-77e9-4574-a521-d487888e4fcf', members=[JoinGroupResponseMember(memberId='consumer-1-ab505c32-77e9-4574-a521-d487888e4fcf', groupInstanceId='null', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 116, 111, 112, 105, 99, 49, 0, 0, 0, 0])])
[framework] 2020-06-20 18:14:57,709 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -610  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Performing assignment using strategy range with subscriptions {consumer-1-ab505c32-77e9-4574-a521-d487888e4fcf=Subscription(topics=[topic1])}
[framework] 2020-06-20 18:14:57,712 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -613  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Finished assignment for group: {consumer-1-ab505c32-77e9-4574-a521-d487888e4fcf=Assignment(partitions=[topic1-0, topic1-1, topic1-2])}
[framework] 2020-06-20 18:14:57,718 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -619  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending leader SyncGroup to coordinator Kafka-1:9092 (id: 2147483646 rack: null): SyncGroupRequestData(groupId='DemoConsumer', generationId=1, memberId='consumer-1-ab505c32-77e9-4574-a521-d487888e4fcf', groupInstanceId='null', assignments=[SyncGroupRequestAssignment(memberId='consumer-1-ab505c32-77e9-4574-a521-d487888e4fcf', assignment=[0, 0, 0, 0, 0, 1, 0, 6, 116, 111, 112, 105, 99, 49, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0])])
[framework] 2020-06-20 18:14:57,718 - org.apache.kafka.common.metrics.Metrics -619  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.records-per-batch
[framework] 2020-06-20 18:14:57,719 - org.apache.kafka.common.metrics.Metrics -620  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.bytes
[framework] 2020-06-20 18:14:57,719 - org.apache.kafka.common.metrics.Metrics -620  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.compression-rate
[framework] 2020-06-20 18:14:57,719 - org.apache.kafka.common.metrics.Metrics -620  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.record-retries
[framework] 2020-06-20 18:14:57,720 - org.apache.kafka.common.metrics.Metrics -621  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.record-errors
[framework] 2020-06-20 18:14:57,735 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -636  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Successfully joined group with generation 1
[framework] 2020-06-20 18:14:57,736 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -637  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Enabling heartbeat thread
[framework] 2020-06-20 18:14:57,738 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -639  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Setting newly assigned partitions: topic1-1, topic1-0, topic1-2
[framework] 2020-06-20 18:14:57,749 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -650  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Fetching committed offsets for partitions: [topic1-1, topic1-0, topic1-2]
[framework] 2020-06-20 18:14:57,813 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -714  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Found no committed offset for partition topic1-1
[framework] 2020-06-20 18:14:57,813 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -714  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Found no committed offset for partition topic1-0
[framework] 2020-06-20 18:14:57,813 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -714  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Found no committed offset for partition topic1-2
[framework] 2020-06-20 18:14:57,819 - org.apache.kafka.clients.consumer.internals.Fetcher -720  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={topic1-1={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[0]}, topic1-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[0]}, topic1-2={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[0]}}, isolationLevel=READ_UNCOMMITTED) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:57,832 - org.apache.kafka.clients.consumer.internals.Fetcher -733  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Handling ListOffsetResponse response for topic1-1. Fetched offset 538, timestamp -1
[framework] 2020-06-20 18:14:57,832 - org.apache.kafka.clients.consumer.internals.Fetcher -733  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Handling ListOffsetResponse response for topic1-0. Fetched offset 504, timestamp -1
[framework] 2020-06-20 18:14:57,832 - org.apache.kafka.clients.consumer.internals.Fetcher -733  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Handling ListOffsetResponse response for topic1-2. Fetched offset 473, timestamp -1
[framework] 2020-06-20 18:14:57,834 - org.apache.kafka.clients.Metadata -735  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Not replacing existing epoch 0 with new epoch 0
[framework] 2020-06-20 18:14:57,834 - org.apache.kafka.clients.consumer.internals.SubscriptionState -735  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Resetting offset for partition topic1-1 to offset 538.
[framework] 2020-06-20 18:14:57,834 - org.apache.kafka.clients.Metadata -735  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Not replacing existing epoch 0 with new epoch 0
[framework] 2020-06-20 18:14:57,834 - org.apache.kafka.clients.consumer.internals.SubscriptionState -735  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Resetting offset for partition topic1-0 to offset 504.
[framework] 2020-06-20 18:14:57,835 - org.apache.kafka.clients.Metadata -736  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Not replacing existing epoch 0 with new epoch 0
[framework] 2020-06-20 18:14:57,835 - org.apache.kafka.clients.consumer.internals.SubscriptionState -736  [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Resetting offset for partition topic1-2 to offset 473.
[framework] 2020-06-20 18:14:57,838 - org.apache.kafka.clients.consumer.internals.Fetcher -739  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=538, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:57,838 - org.apache.kafka.clients.consumer.internals.Fetcher -739  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=504, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:57,838 - org.apache.kafka.clients.consumer.internals.Fetcher -739  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=473, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:57,838 - org.apache.kafka.clients.FetchSessionHandler -739  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 1 with 3 partition(s).
[framework] 2020-06-20 18:14:57,840 - org.apache.kafka.clients.consumer.internals.Fetcher -741  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending READ_UNCOMMITTED FullFetchRequest(topic1-1, topic1-0, topic1-2) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:58,079 - org.apache.kafka.clients.FetchSessionHandler -980  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Node 1 sent a full fetch response that created a new incremental fetch session 1929414518 with 3 response partition(s)
[framework] 2020-06-20 18:14:58,081 - org.apache.kafka.clients.consumer.internals.Fetcher -982  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 538 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=538, lastStableOffset = 538, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=0)
[framework] 2020-06-20 18:14:58,095 - org.apache.kafka.clients.consumer.internals.Fetcher -996  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 504 for partition topic1-0 returned fetch data (error=NONE, highWaterMark=1186, lastStableOffset = 1186, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=16365)
[framework] 2020-06-20 18:14:58,095 - org.apache.kafka.clients.consumer.internals.Fetcher -996  [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 473 for partition topic1-2 returned fetch data (error=NONE, highWaterMark=473, lastStableOffset = 473, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=0)
[framework] 2020-06-20 18:14:58,096 - org.apache.kafka.common.metrics.Metrics -997  [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic1-1.records-lag
[framework] 2020-06-20 18:14:58,097 - org.apache.kafka.common.metrics.Metrics -998  [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic1-1.records-lead
[framework] 2020-06-20 18:14:58,123 - org.apache.kafka.common.metrics.Metrics -1024 [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic1-0.records-lag
[framework] 2020-06-20 18:14:58,123 - org.apache.kafka.common.metrics.Metrics -1024 [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic1-0.records-lead
[framework] 2020-06-20 18:14:58,124 - org.apache.kafka.clients.consumer.internals.Fetcher -1025 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=538, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:58,124 - org.apache.kafka.clients.FetchSessionHandler -1025 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Built incremental fetch (sessionId=1929414518, epoch=1) for node 1. Added 0 partition(s), altered 0 partition(s), removed 2 partition(s) out of 1 partition(s)
[framework] 2020-06-20 18:14:58,124 - org.apache.kafka.clients.consumer.internals.Fetcher -1025 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(topic1-0, topic1-2), implied=(topic1-1)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:58,140 - org.apache.kafka.clients.consumer.KafkaConsumer -1041 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:58,142 - org.apache.kafka.common.metrics.Metrics -1043 [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.bytes-fetched
[framework] 2020-06-20 18:14:58,143 - org.apache.kafka.common.metrics.Metrics -1044 [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.records-fetched
[framework] 2020-06-20 18:14:58,143 - org.apache.kafka.common.metrics.Metrics -1044 [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic1-2.records-lag
[framework] 2020-06-20 18:14:58,152 - org.apache.kafka.common.metrics.Metrics -1053 [KafkaConsumerExample] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic1-2.records-lead
[framework] 2020-06-20 18:14:58,154 - org.apache.kafka.clients.consumer.KafkaConsumer -1055 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:58,500 - org.apache.kafka.clients.FetchSessionHandler -1401 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1929414518 with 1 response partition(s)
[framework] 2020-06-20 18:14:58,500 - org.apache.kafka.clients.consumer.internals.Fetcher -1401 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 538 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=3266, lastStableOffset = 3266, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=65460)
[framework] 2020-06-20 18:14:58,517 - org.apache.kafka.clients.consumer.internals.Fetcher -1418 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=473, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:58,517 - org.apache.kafka.clients.consumer.internals.Fetcher -1418 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=1186, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:58,517 - org.apache.kafka.clients.FetchSessionHandler -1418 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Built incremental fetch (sessionId=1929414518, epoch=2) for node 1. Added 2 partition(s), altered 0 partition(s), removed 1 partition(s) out of 2 partition(s)
[framework] 2020-06-20 18:14:58,517 - org.apache.kafka.clients.consumer.internals.Fetcher -1418 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-2, topic1-0), toForget=(topic1-1), implied=()) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:58,520 - org.apache.kafka.clients.consumer.KafkaConsumer -1421 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:58,526 - org.apache.kafka.clients.consumer.KafkaConsumer -1427 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:58,543 - org.apache.kafka.clients.consumer.KafkaConsumer -1444 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:58,551 - org.apache.kafka.clients.consumer.KafkaConsumer -1452 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:58,578 - org.apache.kafka.clients.consumer.KafkaConsumer -1479 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:58,581 - org.apache.kafka.clients.consumer.KafkaConsumer -1482 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:58,739 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -1640 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=3266, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=1186, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=473, leaderEpoch=null, metadata=''}}
[framework] 2020-06-20 18:14:58,789 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -1690 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 3266 for partition topic1-1
[framework] 2020-06-20 18:14:58,789 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -1690 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 1186 for partition topic1-0
[framework] 2020-06-20 18:14:58,789 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -1690 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 473 for partition topic1-2
[framework] 2020-06-20 18:14:58,790 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -1691 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=3266, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=1186, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=473, leaderEpoch=null, metadata=''}}
[framework] 2020-06-20 18:14:59,894 - org.apache.kafka.clients.FetchSessionHandler -2795 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1929414518 with 2 response partition(s)
[framework] 2020-06-20 18:14:59,895 - org.apache.kafka.clients.consumer.internals.Fetcher -2796 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 473 for partition topic1-2 returned fetch data (error=NONE, highWaterMark=5165, lastStableOffset = 5165, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=114579)
[framework] 2020-06-20 18:14:59,895 - org.apache.kafka.clients.consumer.internals.Fetcher -2796 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 1186 for partition topic1-0 returned fetch data (error=NONE, highWaterMark=5205, lastStableOffset = 5205, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=98207)
[framework] 2020-06-20 18:14:59,896 - org.apache.kafka.clients.consumer.internals.Fetcher -2797 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=3266, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:59,896 - org.apache.kafka.clients.FetchSessionHandler -2797 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Built incremental fetch (sessionId=1929414518, epoch=3) for node 1. Added 1 partition(s), altered 0 partition(s), removed 2 partition(s) out of 1 partition(s)
[framework] 2020-06-20 18:14:59,896 - org.apache.kafka.clients.consumer.internals.Fetcher -2797 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(topic1-2, topic1-0), implied=()) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:14:59,900 - org.apache.kafka.clients.consumer.KafkaConsumer -2801 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,901 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -2802 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=3266, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=1186, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=973, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:14:59,910 - org.apache.kafka.clients.consumer.KafkaConsumer -2811 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,914 - org.apache.kafka.clients.consumer.KafkaConsumer -2815 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,918 - org.apache.kafka.clients.consumer.KafkaConsumer -2819 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,922 - org.apache.kafka.clients.consumer.KafkaConsumer -2823 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,926 - org.apache.kafka.clients.consumer.KafkaConsumer -2827 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,929 - org.apache.kafka.clients.consumer.KafkaConsumer -2830 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,933 - org.apache.kafka.clients.consumer.KafkaConsumer -2834 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,940 - org.apache.kafka.clients.consumer.KafkaConsumer -2841 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,947 - org.apache.kafka.clients.consumer.KafkaConsumer -2848 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,953 - org.apache.kafka.clients.consumer.KafkaConsumer -2854 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,955 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -2856 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 3266 for partition topic1-1
[framework] 2020-06-20 18:14:59,955 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -2856 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 1186 for partition topic1-0
[framework] 2020-06-20 18:14:59,955 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -2856 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 973 for partition topic1-2
[framework] 2020-06-20 18:14:59,958 - org.apache.kafka.clients.consumer.KafkaConsumer -2859 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,958 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -2859 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=3266, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=1186, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=973, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:14:59,964 - org.apache.kafka.clients.consumer.KafkaConsumer -2865 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,967 - org.apache.kafka.clients.consumer.KafkaConsumer -2868 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,971 - org.apache.kafka.clients.consumer.KafkaConsumer -2872 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,974 - org.apache.kafka.clients.consumer.KafkaConsumer -2875 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,977 - org.apache.kafka.clients.consumer.KafkaConsumer -2878 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:14:59,979 - org.apache.kafka.clients.consumer.KafkaConsumer -2880 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:00,736 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -3637 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending Heartbeat request to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-20 18:15:00,775 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -3676 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Received successful Heartbeat response
[framework] 2020-06-20 18:15:00,902 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -3803 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=3266, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:00,942 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -3843 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 3266 for partition topic1-1
[framework] 2020-06-20 18:15:00,942 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -3843 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5205 for partition topic1-0
[framework] 2020-06-20 18:15:00,942 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -3843 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5165 for partition topic1-2
[framework] 2020-06-20 18:15:00,942 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -3843 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=3266, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:00,980 - org.apache.kafka.clients.consumer.KafkaConsumer -3881 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,250 - org.apache.kafka.clients.FetchSessionHandler -4151 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1929414518 with 1 response partition(s)
[framework] 2020-06-20 18:15:01,251 - org.apache.kafka.clients.consumer.internals.Fetcher -4152 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 3266 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=12441, lastStableOffset = 12441, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=229209)
[framework] 2020-06-20 18:15:01,252 - org.apache.kafka.clients.consumer.internals.Fetcher -4153 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=5165, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:15:01,252 - org.apache.kafka.clients.consumer.internals.Fetcher -4153 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=5205, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:15:01,253 - org.apache.kafka.clients.FetchSessionHandler -4154 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Built incremental fetch (sessionId=1929414518, epoch=4) for node 1. Added 2 partition(s), altered 0 partition(s), removed 1 partition(s) out of 2 partition(s)
[framework] 2020-06-20 18:15:01,253 - org.apache.kafka.clients.consumer.internals.Fetcher -4154 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-2, topic1-0), toForget=(topic1-1), implied=()) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:15:01,258 - org.apache.kafka.clients.consumer.KafkaConsumer -4159 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,262 - org.apache.kafka.clients.consumer.KafkaConsumer -4163 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,264 - org.apache.kafka.clients.consumer.KafkaConsumer -4165 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,267 - org.apache.kafka.clients.consumer.KafkaConsumer -4168 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,269 - org.apache.kafka.clients.consumer.KafkaConsumer -4170 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,273 - org.apache.kafka.clients.consumer.KafkaConsumer -4174 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,276 - org.apache.kafka.clients.consumer.KafkaConsumer -4177 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,279 - org.apache.kafka.clients.consumer.KafkaConsumer -4180 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,369 - org.apache.kafka.clients.consumer.KafkaConsumer -4270 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,373 - org.apache.kafka.clients.consumer.KafkaConsumer -4274 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,377 - org.apache.kafka.clients.consumer.KafkaConsumer -4278 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,381 - org.apache.kafka.clients.consumer.KafkaConsumer -4282 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,385 - org.apache.kafka.clients.consumer.KafkaConsumer -4286 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,389 - org.apache.kafka.clients.consumer.KafkaConsumer -4290 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,393 - org.apache.kafka.clients.consumer.KafkaConsumer -4294 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,397 - org.apache.kafka.clients.consumer.KafkaConsumer -4298 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,402 - org.apache.kafka.clients.consumer.KafkaConsumer -4303 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,407 - org.apache.kafka.clients.consumer.KafkaConsumer -4308 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,410 - org.apache.kafka.clients.consumer.KafkaConsumer -4311 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:01,903 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -4804 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:02,411 - org.apache.kafka.clients.consumer.KafkaConsumer -5312 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:02,422 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5323 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 12441 for partition topic1-1
[framework] 2020-06-20 18:15:02,422 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5323 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5205 for partition topic1-0
[framework] 2020-06-20 18:15:02,423 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5324 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5165 for partition topic1-2
[framework] 2020-06-20 18:15:02,423 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5324 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:02,903 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5804 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:02,978 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5879 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 12441 for partition topic1-1
[framework] 2020-06-20 18:15:02,978 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5879 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5205 for partition topic1-0
[framework] 2020-06-20 18:15:02,978 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5879 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5165 for partition topic1-2
[framework] 2020-06-20 18:15:02,978 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5879 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:03,413 - org.apache.kafka.clients.consumer.KafkaConsumer -6314 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:03,737 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -6638 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending Heartbeat request to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-20 18:15:03,796 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -6697 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Received successful Heartbeat response
[framework] 2020-06-20 18:15:03,904 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -6805 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:04,011 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -6912 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 12441 for partition topic1-1
[framework] 2020-06-20 18:15:04,011 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -6912 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5205 for partition topic1-0
[framework] 2020-06-20 18:15:04,011 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -6912 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5165 for partition topic1-2
[framework] 2020-06-20 18:15:04,011 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -6912 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:04,413 - org.apache.kafka.clients.consumer.KafkaConsumer -7314 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:04,903 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -7804 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:05,028 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -7929 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 12441 for partition topic1-1
[framework] 2020-06-20 18:15:05,029 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -7930 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5205 for partition topic1-0
[framework] 2020-06-20 18:15:05,029 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -7930 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5165 for partition topic1-2
[framework] 2020-06-20 18:15:05,029 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -7930 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:05,415 - org.apache.kafka.clients.consumer.KafkaConsumer -8316 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:05,904 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -8805 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:06,025 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -8926 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 12441 for partition topic1-1
[framework] 2020-06-20 18:15:06,025 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -8926 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5205 for partition topic1-0
[framework] 2020-06-20 18:15:06,025 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -8926 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5165 for partition topic1-2
[framework] 2020-06-20 18:15:06,025 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -8926 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:06,416 - org.apache.kafka.clients.consumer.KafkaConsumer -9317 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:06,737 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -9638 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending Heartbeat request to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-20 18:15:06,904 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -9805 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:07,117 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -10018 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Received successful Heartbeat response
[framework] 2020-06-20 18:15:07,117 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10018 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 12441 for partition topic1-1
[framework] 2020-06-20 18:15:07,117 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10018 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5205 for partition topic1-0
[framework] 2020-06-20 18:15:07,118 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10019 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5165 for partition topic1-2
[framework] 2020-06-20 18:15:07,118 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10019 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:07,417 - org.apache.kafka.clients.consumer.KafkaConsumer -10318 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:07,905 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10806 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:08,037 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10938 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 12441 for partition topic1-1
[framework] 2020-06-20 18:15:08,037 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10938 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5205 for partition topic1-0
[framework] 2020-06-20 18:15:08,037 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10938 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 5165 for partition topic1-2
[framework] 2020-06-20 18:15:08,037 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10938 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=5205, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=5165, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:08,124 - org.apache.kafka.clients.FetchSessionHandler -11025 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1929414518 with 2 response partition(s)
[framework] 2020-06-20 18:15:08,124 - org.apache.kafka.clients.consumer.internals.Fetcher -11025 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 5165 for partition topic1-2 returned fetch data (error=NONE, highWaterMark=21540, lastStableOffset = 21540, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=409300)
[framework] 2020-06-20 18:15:08,124 - org.apache.kafka.clients.consumer.internals.Fetcher -11025 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 5205 for partition topic1-0 returned fetch data (error=NONE, highWaterMark=21580, lastStableOffset = 21580, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=409300)
[framework] 2020-06-20 18:15:08,125 - org.apache.kafka.clients.consumer.internals.Fetcher -11026 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=12441, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:15:08,125 - org.apache.kafka.clients.FetchSessionHandler -11026 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Built incremental fetch (sessionId=1929414518, epoch=5) for node 1. Added 1 partition(s), altered 0 partition(s), removed 2 partition(s) out of 1 partition(s)
[framework] 2020-06-20 18:15:08,125 - org.apache.kafka.clients.consumer.internals.Fetcher -11026 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(topic1-2, topic1-0), implied=()) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-20 18:15:08,142 - org.apache.kafka.clients.consumer.KafkaConsumer -11043 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,144 - org.apache.kafka.clients.consumer.KafkaConsumer -11045 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,147 - org.apache.kafka.clients.consumer.KafkaConsumer -11048 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,149 - org.apache.kafka.clients.consumer.KafkaConsumer -11050 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,151 - org.apache.kafka.clients.consumer.KafkaConsumer -11052 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,153 - org.apache.kafka.clients.consumer.KafkaConsumer -11054 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,155 - org.apache.kafka.clients.consumer.KafkaConsumer -11056 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,157 - org.apache.kafka.clients.consumer.KafkaConsumer -11058 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,158 - org.apache.kafka.clients.consumer.KafkaConsumer -11059 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,161 - org.apache.kafka.clients.consumer.KafkaConsumer -11062 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,163 - org.apache.kafka.clients.consumer.KafkaConsumer -11064 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,165 - org.apache.kafka.clients.consumer.KafkaConsumer -11066 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,167 - org.apache.kafka.clients.consumer.KafkaConsumer -11068 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,168 - org.apache.kafka.clients.consumer.KafkaConsumer -11069 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,170 - org.apache.kafka.clients.consumer.KafkaConsumer -11071 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,172 - org.apache.kafka.clients.consumer.KafkaConsumer -11073 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,174 - org.apache.kafka.clients.consumer.KafkaConsumer -11075 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,176 - org.apache.kafka.clients.consumer.KafkaConsumer -11077 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,177 - org.apache.kafka.clients.consumer.KafkaConsumer -11078 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,179 - org.apache.kafka.clients.consumer.KafkaConsumer -11080 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,181 - org.apache.kafka.clients.consumer.KafkaConsumer -11082 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,183 - org.apache.kafka.clients.consumer.KafkaConsumer -11084 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,184 - org.apache.kafka.clients.consumer.KafkaConsumer -11085 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,186 - org.apache.kafka.clients.consumer.KafkaConsumer -11087 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,188 - org.apache.kafka.clients.consumer.KafkaConsumer -11089 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,190 - org.apache.kafka.clients.consumer.KafkaConsumer -11091 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,191 - org.apache.kafka.clients.consumer.KafkaConsumer -11092 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,193 - org.apache.kafka.clients.consumer.KafkaConsumer -11094 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,195 - org.apache.kafka.clients.consumer.KafkaConsumer -11096 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,196 - org.apache.kafka.clients.consumer.KafkaConsumer -11097 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,198 - org.apache.kafka.clients.consumer.KafkaConsumer -11099 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,200 - org.apache.kafka.clients.consumer.KafkaConsumer -11101 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,201 - org.apache.kafka.clients.consumer.KafkaConsumer -11102 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,203 - org.apache.kafka.clients.consumer.KafkaConsumer -11104 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,205 - org.apache.kafka.clients.consumer.KafkaConsumer -11106 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,206 - org.apache.kafka.clients.consumer.KafkaConsumer -11107 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,208 - org.apache.kafka.clients.consumer.KafkaConsumer -11109 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,210 - org.apache.kafka.clients.consumer.KafkaConsumer -11111 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,211 - org.apache.kafka.clients.consumer.KafkaConsumer -11112 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,213 - org.apache.kafka.clients.consumer.KafkaConsumer -11114 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,214 - org.apache.kafka.clients.consumer.KafkaConsumer -11115 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,216 - org.apache.kafka.clients.consumer.KafkaConsumer -11117 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,217 - org.apache.kafka.clients.consumer.KafkaConsumer -11118 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,219 - org.apache.kafka.clients.consumer.KafkaConsumer -11120 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,221 - org.apache.kafka.clients.consumer.KafkaConsumer -11122 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,223 - org.apache.kafka.clients.consumer.KafkaConsumer -11124 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,224 - org.apache.kafka.clients.consumer.KafkaConsumer -11125 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,226 - org.apache.kafka.clients.consumer.KafkaConsumer -11127 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,228 - org.apache.kafka.clients.consumer.KafkaConsumer -11129 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,230 - org.apache.kafka.clients.consumer.KafkaConsumer -11131 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,232 - org.apache.kafka.clients.consumer.KafkaConsumer -11133 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,235 - org.apache.kafka.clients.consumer.KafkaConsumer -11136 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,237 - org.apache.kafka.clients.consumer.KafkaConsumer -11138 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,239 - org.apache.kafka.clients.consumer.KafkaConsumer -11140 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,241 - org.apache.kafka.clients.consumer.KafkaConsumer -11142 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,243 - org.apache.kafka.clients.consumer.KafkaConsumer -11144 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,245 - org.apache.kafka.clients.consumer.KafkaConsumer -11146 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,246 - org.apache.kafka.clients.consumer.KafkaConsumer -11147 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,248 - org.apache.kafka.clients.consumer.KafkaConsumer -11149 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,250 - org.apache.kafka.clients.consumer.KafkaConsumer -11151 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,252 - org.apache.kafka.clients.consumer.KafkaConsumer -11153 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,253 - org.apache.kafka.clients.consumer.KafkaConsumer -11154 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,255 - org.apache.kafka.clients.consumer.KafkaConsumer -11156 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,256 - org.apache.kafka.clients.consumer.KafkaConsumer -11157 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,258 - org.apache.kafka.clients.consumer.KafkaConsumer -11159 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,259 - org.apache.kafka.clients.consumer.KafkaConsumer -11160 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:08,906 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -11807 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=21580, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=21540, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:09,076 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -11977 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 12441 for partition topic1-1
[framework] 2020-06-20 18:15:09,076 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -11977 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 21580 for partition topic1-0
[framework] 2020-06-20 18:15:09,076 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -11977 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 21540 for partition topic1-2
[framework] 2020-06-20 18:15:09,077 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -11978 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=21580, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=21540, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:09,260 - org.apache.kafka.clients.consumer.KafkaConsumer -12161 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:09,738 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -12639 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending Heartbeat request to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-20 18:15:09,853 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -12754 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Received successful Heartbeat response
[framework] 2020-06-20 18:15:09,905 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -12806 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=21580, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=21540, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:10,029 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -12930 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 12441 for partition topic1-1
[framework] 2020-06-20 18:15:10,029 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -12930 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 21580 for partition topic1-0
[framework] 2020-06-20 18:15:10,029 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -12930 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 21540 for partition topic1-2
[framework] 2020-06-20 18:15:10,029 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -12930 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=21580, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=21540, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:10,261 - org.apache.kafka.clients.consumer.KafkaConsumer -13162 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-20 18:15:10,906 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -13807 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=21580, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=21540, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:10,957 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -13858 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 12441 for partition topic1-1
[framework] 2020-06-20 18:15:10,957 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -13858 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 21580 for partition topic1-0
[framework] 2020-06-20 18:15:10,957 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -13858 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Committed offset 21540 for partition topic1-2
[framework] 2020-06-20 18:15:10,957 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -13858 [KafkaConsumerExample] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=12441, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=21580, leaderEpoch=0, metadata=''}, topic1-2=OffsetAndMetadata{offset=21540, leaderEpoch=0, metadata=''}}
[framework] 2020-06-20 18:15:11,262 - org.apache.kafka.clients.consumer.KafkaConsumer -14163 [KafkaConsumerExample] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer-1, groupId=DemoConsumer] Subscribed to topic(s): topic1
