[framework] 2020-06-22 08:51:50,450 - org.apache.kafka.clients.producer.ProducerConfig -0    [main] INFO  org.apache.kafka.clients.producer.ProducerConfig  - ProducerConfig values: 
	acks = all
	batch.size = 1000
	bootstrap.servers = [kafka-1:9092]
	buffer.memory = 2048000
	client.dns.lookup = default
	client.id = DemoProducer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class cn.neyzoter.module.kafka.AllocationPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[framework] 2020-06-22 08:51:50,520 - org.apache.kafka.common.metrics.Metrics -70   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bufferpool-wait-time
[framework] 2020-06-22 08:51:50,526 - org.apache.kafka.common.metrics.Metrics -76   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name buffer-exhausted-records
[framework] 2020-06-22 08:51:50,532 - org.apache.kafka.common.metrics.Metrics -82   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name errors
[framework] 2020-06-22 08:51:50,541 - org.apache.kafka.common.metrics.Metrics -91   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name produce-throttle-time
[framework] 2020-06-22 08:51:50,549 - org.apache.kafka.common.metrics.Metrics -99   [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-closed:
[framework] 2020-06-22 08:51:50,550 - org.apache.kafka.common.metrics.Metrics -100  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-created:
[framework] 2020-06-22 08:51:50,550 - org.apache.kafka.common.metrics.Metrics -100  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication:
[framework] 2020-06-22 08:51:50,550 - org.apache.kafka.common.metrics.Metrics -100  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-reauthentication:
[framework] 2020-06-22 08:51:50,551 - org.apache.kafka.common.metrics.Metrics -101  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication-no-reauth:
[framework] 2020-06-22 08:51:50,551 - org.apache.kafka.common.metrics.Metrics -101  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-authentication:
[framework] 2020-06-22 08:51:50,551 - org.apache.kafka.common.metrics.Metrics -101  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-reauthentication:
[framework] 2020-06-22 08:51:50,551 - org.apache.kafka.common.metrics.Metrics -101  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name reauthentication-latency:
[framework] 2020-06-22 08:51:50,552 - org.apache.kafka.common.metrics.Metrics -102  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent-received:
[framework] 2020-06-22 08:51:50,552 - org.apache.kafka.common.metrics.Metrics -102  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent:
[framework] 2020-06-22 08:51:50,553 - org.apache.kafka.common.metrics.Metrics -103  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-received:
[framework] 2020-06-22 08:51:50,554 - org.apache.kafka.common.metrics.Metrics -104  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name select-time:
[framework] 2020-06-22 08:51:50,555 - org.apache.kafka.common.metrics.Metrics -105  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name io-time:
[framework] 2020-06-22 08:51:50,601 - org.apache.kafka.common.metrics.Metrics -151  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name batch-size
[framework] 2020-06-22 08:51:50,601 - org.apache.kafka.common.metrics.Metrics -151  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name compression-rate
[framework] 2020-06-22 08:51:50,602 - org.apache.kafka.common.metrics.Metrics -152  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name queue-time
[framework] 2020-06-22 08:51:50,602 - org.apache.kafka.common.metrics.Metrics -152  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name request-time
[framework] 2020-06-22 08:51:50,602 - org.apache.kafka.common.metrics.Metrics -152  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-per-request
[framework] 2020-06-22 08:51:50,603 - org.apache.kafka.common.metrics.Metrics -153  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name record-retries
[framework] 2020-06-22 08:51:50,603 - org.apache.kafka.common.metrics.Metrics -153  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name record-size
[framework] 2020-06-22 08:51:50,606 - org.apache.kafka.common.metrics.Metrics -156  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name batch-split-rate
[framework] 2020-06-22 08:51:50,607 - org.apache.kafka.clients.producer.internals.Sender -157  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.producer.internals.Sender  - [Producer clientId=DemoProducer] Starting Kafka producer I/O thread.
[framework] 2020-06-22 08:51:50,610 - org.apache.kafka.common.utils.AppInfoParser -160  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka version: 2.3.0
[framework] 2020-06-22 08:51:50,610 - org.apache.kafka.common.utils.AppInfoParser -160  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka commitId: fc1aaa116b661c8a
[framework] 2020-06-22 08:51:50,610 - org.apache.kafka.common.utils.AppInfoParser -160  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka startTimeMs: 1592787110607
[framework] 2020-06-22 08:51:50,611 - org.apache.kafka.clients.producer.KafkaProducer -161  [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer  - [Producer clientId=DemoProducer] Kafka producer started
[framework] 2020-06-22 08:51:50,633 - org.apache.kafka.clients.NetworkClient -183  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initialize connection to node kafka-1:9092 (id: -1 rack: null) for sending metadata request
[framework] 2020-06-22 08:51:50,634 - org.apache.kafka.clients.NetworkClient -184  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating connection to node kafka-1:9092 (id: -1 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-22 08:51:50,642 - org.apache.kafka.common.metrics.Metrics -192  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-sent
[framework] 2020-06-22 08:51:50,643 - org.apache.kafka.common.metrics.Metrics -193  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-received
[framework] 2020-06-22 08:51:50,644 - org.apache.kafka.common.metrics.Metrics -194  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.latency
[framework] 2020-06-22 08:51:50,644 - org.apache.kafka.common.network.Selector -194  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.network.Selector  - [Producer clientId=DemoProducer] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
[framework] 2020-06-22 08:51:50,652 - kafka.utils.Log4jControllerRegistration$ -202  [main] INFO  kafka.utils.Log4jControllerRegistration$  - Registered kafka:type=kafka.Log4jController MBean
[framework] 2020-06-22 08:51:50,659 - org.apache.kafka.clients.consumer.ConsumerConfig -209  [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig  - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [kafka-1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = consumer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = DemoConsumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[framework] 2020-06-22 08:51:50,659 - org.apache.kafka.clients.consumer.KafkaConsumer -209  [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Initializing the Kafka consumer
[framework] 2020-06-22 08:51:50,668 - org.apache.kafka.common.metrics.Metrics -218  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-throttle-time
[framework] 2020-06-22 08:51:50,669 - org.apache.kafka.common.metrics.Metrics -219  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-closed:
[framework] 2020-06-22 08:51:50,669 - org.apache.kafka.common.metrics.Metrics -219  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-created:
[framework] 2020-06-22 08:51:50,669 - org.apache.kafka.common.metrics.Metrics -219  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication:
[framework] 2020-06-22 08:51:50,669 - org.apache.kafka.common.metrics.Metrics -219  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-reauthentication:
[framework] 2020-06-22 08:51:50,670 - org.apache.kafka.common.metrics.Metrics -220  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication-no-reauth:
[framework] 2020-06-22 08:51:50,670 - org.apache.kafka.common.metrics.Metrics -220  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-authentication:
[framework] 2020-06-22 08:51:50,670 - org.apache.kafka.common.metrics.Metrics -220  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-reauthentication:
[framework] 2020-06-22 08:51:50,670 - org.apache.kafka.common.metrics.Metrics -220  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name reauthentication-latency:
[framework] 2020-06-22 08:51:50,671 - org.apache.kafka.common.metrics.Metrics -221  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent-received:
[framework] 2020-06-22 08:51:50,671 - org.apache.kafka.common.metrics.Metrics -221  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent:
[framework] 2020-06-22 08:51:50,672 - org.apache.kafka.common.metrics.Metrics -222  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-received:
[framework] 2020-06-22 08:51:50,672 - org.apache.kafka.common.metrics.Metrics -222  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name select-time:
[framework] 2020-06-22 08:51:50,673 - org.apache.kafka.common.metrics.Metrics -223  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name io-time:
[framework] 2020-06-22 08:51:50,686 - org.apache.kafka.common.metrics.Metrics -236  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name heartbeat-latency
[framework] 2020-06-22 08:51:50,687 - org.apache.kafka.common.metrics.Metrics -237  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name join-latency
[framework] 2020-06-22 08:51:50,687 - org.apache.kafka.common.metrics.Metrics -237  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name sync-latency
[framework] 2020-06-22 08:51:50,689 - org.apache.kafka.common.metrics.Metrics -239  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name commit-latency
[framework] 2020-06-22 08:51:50,692 - org.apache.kafka.common.metrics.Metrics -242  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-fetched
[framework] 2020-06-22 08:51:50,692 - org.apache.kafka.common.metrics.Metrics -242  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-fetched
[framework] 2020-06-22 08:51:50,692 - org.apache.kafka.common.metrics.Metrics -242  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-latency
[framework] 2020-06-22 08:51:50,693 - org.apache.kafka.common.metrics.Metrics -243  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lag
[framework] 2020-06-22 08:51:50,693 - org.apache.kafka.common.metrics.Metrics -243  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lead
[framework] 2020-06-22 08:51:50,696 - org.apache.kafka.common.utils.AppInfoParser -246  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka version: 2.3.0
[framework] 2020-06-22 08:51:50,696 - org.apache.kafka.common.utils.AppInfoParser -246  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka commitId: fc1aaa116b661c8a
[framework] 2020-06-22 08:51:50,696 - org.apache.kafka.common.utils.AppInfoParser -246  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka startTimeMs: 1592787110695
[framework] 2020-06-22 08:51:50,696 - org.apache.kafka.clients.consumer.KafkaConsumer -246  [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Kafka consumer initialized
[framework] 2020-06-22 08:51:50,697 - org.apache.kafka.clients.consumer.ConsumerConfig -247  [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig  - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [kafka-1:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = consumer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = DemoConsumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[framework] 2020-06-22 08:51:50,697 - org.apache.kafka.clients.consumer.KafkaConsumer -247  [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Initializing the Kafka consumer
[framework] 2020-06-22 08:51:50,698 - org.apache.kafka.common.metrics.Metrics -248  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-throttle-time
[framework] 2020-06-22 08:51:50,699 - org.apache.kafka.common.metrics.Metrics -249  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-closed:
[framework] 2020-06-22 08:51:50,699 - org.apache.kafka.common.metrics.Metrics -249  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name connections-created:
[framework] 2020-06-22 08:51:50,699 - org.apache.kafka.common.metrics.Metrics -249  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication:
[framework] 2020-06-22 08:51:50,700 - org.apache.kafka.common.metrics.Metrics -250  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-reauthentication:
[framework] 2020-06-22 08:51:50,700 - org.apache.kafka.common.metrics.Metrics -250  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name successful-authentication-no-reauth:
[framework] 2020-06-22 08:51:50,700 - org.apache.kafka.common.metrics.Metrics -250  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-authentication:
[framework] 2020-06-22 08:51:50,700 - org.apache.kafka.common.metrics.Metrics -250  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name failed-reauthentication:
[framework] 2020-06-22 08:51:50,701 - org.apache.kafka.common.metrics.Metrics -251  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name reauthentication-latency:
[framework] 2020-06-22 08:51:50,701 - org.apache.kafka.common.metrics.Metrics -251  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent-received:
[framework] 2020-06-22 08:51:50,701 - org.apache.kafka.common.metrics.Metrics -251  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-sent:
[framework] 2020-06-22 08:51:50,702 - org.apache.kafka.common.metrics.Metrics -252  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-received:
[framework] 2020-06-22 08:51:50,703 - org.apache.kafka.common.metrics.Metrics -253  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name select-time:
[framework] 2020-06-22 08:51:50,703 - org.apache.kafka.common.metrics.Metrics -253  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name io-time:
[framework] 2020-06-22 08:51:50,704 - org.apache.kafka.common.metrics.Metrics -254  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name heartbeat-latency
[framework] 2020-06-22 08:51:50,704 - org.apache.kafka.common.metrics.Metrics -254  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name join-latency
[framework] 2020-06-22 08:51:50,705 - org.apache.kafka.common.metrics.Metrics -255  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name sync-latency
[framework] 2020-06-22 08:51:50,705 - org.apache.kafka.common.metrics.Metrics -255  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name commit-latency
[framework] 2020-06-22 08:51:50,706 - org.apache.kafka.common.metrics.Metrics -256  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name bytes-fetched
[framework] 2020-06-22 08:51:50,706 - org.apache.kafka.common.metrics.Metrics -256  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-fetched
[framework] 2020-06-22 08:51:50,707 - org.apache.kafka.common.metrics.Metrics -257  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name fetch-latency
[framework] 2020-06-22 08:51:50,707 - org.apache.kafka.common.metrics.Metrics -257  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lag
[framework] 2020-06-22 08:51:50,707 - org.apache.kafka.common.metrics.Metrics -257  [main] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name records-lead
[framework] 2020-06-22 08:51:50,707 - org.apache.kafka.common.utils.AppInfoParser -257  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka version: 2.3.0
[framework] 2020-06-22 08:51:50,707 - org.apache.kafka.common.utils.AppInfoParser -257  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka commitId: fc1aaa116b661c8a
[framework] 2020-06-22 08:51:50,707 - org.apache.kafka.common.utils.AppInfoParser -257  [main] INFO  org.apache.kafka.common.utils.AppInfoParser  - Kafka startTimeMs: 1592787110707
[framework] 2020-06-22 08:51:50,708 - org.apache.kafka.common.utils.AppInfoParser -258  [main] WARN  org.apache.kafka.common.utils.AppInfoParser  - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=consumer
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:821)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:664)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:644)
	at cn.neyzoter.module.kafka.KafkaComsumerCli.<init>(KafkaComsumerCli.java:34)
	at cn.neyzoter.module.kafka.KafkaApp.main(KafkaApp.java:16)
[framework] 2020-06-22 08:51:50,711 - org.apache.kafka.clients.consumer.KafkaConsumer -261  [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Kafka consumer initialized
[framework] 2020-06-22 08:51:50,714 - cn.neyzoter.module.kafka.KafkaComsumerCli -264  [KafkaConsumerExample_name] INFO  cn.neyzoter.module.kafka.KafkaComsumerCli  - [KafkaConsumerExample_name]: Starting
[framework] 2020-06-22 08:51:50,715 - org.apache.kafka.clients.consumer.KafkaConsumer -265  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:50,717 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -267  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending FindCoordinator request to broker kafka-1:9092 (id: -1 rack: null)
[framework] 2020-06-22 08:51:50,725 - cn.neyzoter.module.kafka.KafkaComsumerCli -275  [KafkaConsumerExample_name] INFO  cn.neyzoter.module.kafka.KafkaComsumerCli  - [KafkaConsumerExample_name]: Starting
[framework] 2020-06-22 08:51:50,725 - org.apache.kafka.clients.consumer.KafkaConsumer -275  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:50,725 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -275  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending FindCoordinator request to broker kafka-1:9092 (id: -1 rack: null)
[framework] 2020-06-22 08:51:50,790 - org.apache.kafka.clients.NetworkClient -340  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Completed connection to node -1. Fetching API versions.
[framework] 2020-06-22 08:51:50,790 - org.apache.kafka.clients.NetworkClient -340  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating API versions fetch from node -1.
[framework] 2020-06-22 08:51:50,791 - org.apache.kafka.clients.NetworkClient -341  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Initiating connection to node kafka-1:9092 (id: -1 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-22 08:51:50,791 - org.apache.kafka.clients.NetworkClient -341  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Initiating connection to node kafka-1:9092 (id: -1 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-22 08:51:50,794 - org.apache.kafka.common.metrics.Metrics -344  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-sent
[framework] 2020-06-22 08:51:50,794 - org.apache.kafka.common.metrics.Metrics -344  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-sent
[framework] 2020-06-22 08:51:50,795 - org.apache.kafka.common.metrics.Metrics -345  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-received
[framework] 2020-06-22 08:51:50,795 - org.apache.kafka.common.metrics.Metrics -345  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.bytes-received
[framework] 2020-06-22 08:51:50,796 - org.apache.kafka.common.metrics.Metrics -346  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.latency
[framework] 2020-06-22 08:51:50,796 - org.apache.kafka.common.metrics.Metrics -346  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node--1.latency
[framework] 2020-06-22 08:51:50,796 - org.apache.kafka.common.network.Selector -346  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=consumer, groupId=DemoConsumer] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
[framework] 2020-06-22 08:51:50,796 - org.apache.kafka.common.network.Selector -346  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=consumer, groupId=DemoConsumer] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
[framework] 2020-06-22 08:51:50,796 - org.apache.kafka.clients.NetworkClient -346  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed connection to node -1. Fetching API versions.
[framework] 2020-06-22 08:51:50,796 - org.apache.kafka.clients.NetworkClient -346  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed connection to node -1. Fetching API versions.
[framework] 2020-06-22 08:51:50,796 - org.apache.kafka.clients.NetworkClient -346  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Initiating API versions fetch from node -1.
[framework] 2020-06-22 08:51:50,796 - org.apache.kafka.clients.NetworkClient -346  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Initiating API versions fetch from node -1.
[framework] 2020-06-22 08:51:50,805 - org.apache.kafka.clients.NetworkClient -355  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-22 08:51:50,805 - org.apache.kafka.clients.NetworkClient -355  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-22 08:51:50,805 - org.apache.kafka.clients.NetworkClient -355  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-22 08:51:50,807 - org.apache.kafka.clients.NetworkClient -357  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='topic1')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node kafka-1:9092 (id: -1 rack: null)
[framework] 2020-06-22 08:51:50,807 - org.apache.kafka.clients.NetworkClient -357  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Sending metadata request MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node kafka-1:9092 (id: -1 rack: null)
[framework] 2020-06-22 08:51:50,807 - org.apache.kafka.clients.NetworkClient -357  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='topic1')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node kafka-1:9092 (id: -1 rack: null)
[framework] 2020-06-22 08:51:50,819 - org.apache.kafka.clients.Metadata -369  [kafka-producer-network-thread | DemoProducer] INFO  org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Cluster ID: MT1saCQCQj6WuKonjf5obA
[framework] 2020-06-22 08:51:50,820 - org.apache.kafka.clients.Metadata -370  [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = MT1saCQCQj6WuKonjf5obA, nodes = [Kafka-1:9092 (id: 1 rack: null), Kafka-1:9093 (id: 2 rack: null)], partitions = [], controller = Kafka-1:9092 (id: 1 rack: null))}
[framework] 2020-06-22 08:51:50,821 - org.apache.kafka.clients.Metadata -371  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer, groupId=DemoConsumer] Updating last seen epoch from null to 0 for partition topic1-0
[framework] 2020-06-22 08:51:50,821 - org.apache.kafka.clients.Metadata -371  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer, groupId=DemoConsumer] Updating last seen epoch from null to 0 for partition topic1-2
[framework] 2020-06-22 08:51:50,821 - org.apache.kafka.clients.Metadata -371  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer, groupId=DemoConsumer] Updating last seen epoch from null to 0 for partition topic1-1
[framework] 2020-06-22 08:51:50,823 - org.apache.kafka.clients.Metadata -373  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer, groupId=DemoConsumer] Cluster ID: MT1saCQCQj6WuKonjf5obA
[framework] 2020-06-22 08:51:50,824 - org.apache.kafka.clients.Metadata -374  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer, groupId=DemoConsumer] Updating last seen epoch from null to 0 for partition topic1-0
[framework] 2020-06-22 08:51:50,824 - org.apache.kafka.clients.Metadata -374  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer, groupId=DemoConsumer] Updating last seen epoch from null to 0 for partition topic1-2
[framework] 2020-06-22 08:51:50,824 - org.apache.kafka.clients.Metadata -374  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer, groupId=DemoConsumer] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = MT1saCQCQj6WuKonjf5obA, nodes = [Kafka-1:9093 (id: 2 rack: null), Kafka-1:9092 (id: 1 rack: null)], partitions = [Partition(topic = topic1, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = topic1, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = topic1, partition = 2, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])], controller = Kafka-1:9092 (id: 1 rack: null))}
[framework] 2020-06-22 08:51:50,824 - org.apache.kafka.clients.Metadata -374  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer, groupId=DemoConsumer] Updating last seen epoch from null to 0 for partition topic1-1
[framework] 2020-06-22 08:51:50,824 - org.apache.kafka.clients.Metadata -374  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer, groupId=DemoConsumer] Cluster ID: MT1saCQCQj6WuKonjf5obA
[framework] 2020-06-22 08:51:50,825 - org.apache.kafka.clients.Metadata -375  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer, groupId=DemoConsumer] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = MT1saCQCQj6WuKonjf5obA, nodes = [Kafka-1:9093 (id: 2 rack: null), Kafka-1:9092 (id: 1 rack: null)], partitions = [Partition(topic = topic1, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = topic1, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = topic1, partition = 2, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])], controller = Kafka-1:9092 (id: 1 rack: null))}
[framework] 2020-06-22 08:51:50,825 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -375  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Received FindCoordinator response ClientResponse(receivedTimeMs=1592787110825, latencyMs=35, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=2, clientId=consumer, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=1, host='Kafka-1', port=9092))
[framework] 2020-06-22 08:51:50,825 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -375  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Received FindCoordinator response ClientResponse(receivedTimeMs=1592787110824, latencyMs=34, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=2, clientId=consumer, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=1, host='Kafka-1', port=9092))
[framework] 2020-06-22 08:51:50,825 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -375  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Discovered group coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:51:50,825 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -375  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Discovered group coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:51:50,825 - org.apache.kafka.clients.NetworkClient -375  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Initiating connection to node Kafka-1:9092 (id: 2147483646 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-22 08:51:50,825 - org.apache.kafka.clients.NetworkClient -375  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Initiating connection to node Kafka-1:9092 (id: 2147483646 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-22 08:51:50,827 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -377  [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Heartbeat thread started
[framework] 2020-06-22 08:51:50,828 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -378  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending synchronous auto-commit of offsets {}
[framework] 2020-06-22 08:51:50,828 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -378  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Revoking previously assigned partitions []
[framework] 2020-06-22 08:51:50,828 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -378  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Disabling heartbeat thread
[framework] 2020-06-22 08:51:50,828 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -378  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] (Re-)joining group
[framework] 2020-06-22 08:51:50,829 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -379  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending synchronous auto-commit of offsets {}
[framework] 2020-06-22 08:51:50,829 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -379  [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Heartbeat thread started
[framework] 2020-06-22 08:51:50,829 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -379  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Joining group with current subscription: [topic1]
[framework] 2020-06-22 08:51:50,829 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -379  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Revoking previously assigned partitions []
[framework] 2020-06-22 08:51:50,829 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -379  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Disabling heartbeat thread
[framework] 2020-06-22 08:51:50,829 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -379  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] (Re-)joining group
[framework] 2020-06-22 08:51:50,829 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -379  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Joining group with current subscription: [topic1]
[framework] 2020-06-22 08:51:50,831 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -381  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending JoinGroup (JoinGroupRequestData(groupId='DemoConsumer', sessionTimeoutMs=30000, rebalanceTimeoutMs=300000, memberId='', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 116, 111, 112, 105, 99, 49, 0, 0, 0, 0])])) to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:51:50,831 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -381  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending JoinGroup (JoinGroupRequestData(groupId='DemoConsumer', sessionTimeoutMs=30000, rebalanceTimeoutMs=300000, memberId='', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 116, 111, 112, 105, 99, 49, 0, 0, 0, 0])])) to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:51:50,832 - org.apache.kafka.common.metrics.Metrics -382  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2147483646.bytes-sent
[framework] 2020-06-22 08:51:50,832 - org.apache.kafka.common.metrics.Metrics -382  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2147483646.bytes-sent
[framework] 2020-06-22 08:51:50,833 - org.apache.kafka.common.metrics.Metrics -383  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2147483646.bytes-received
[framework] 2020-06-22 08:51:50,833 - org.apache.kafka.common.metrics.Metrics -383  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2147483646.bytes-received
[framework] 2020-06-22 08:51:50,834 - org.apache.kafka.common.metrics.Metrics -384  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2147483646.latency
[framework] 2020-06-22 08:51:50,834 - org.apache.kafka.common.metrics.Metrics -384  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2147483646.latency
[framework] 2020-06-22 08:51:50,834 - org.apache.kafka.common.network.Selector -384  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=consumer, groupId=DemoConsumer] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483646
[framework] 2020-06-22 08:51:50,834 - org.apache.kafka.common.network.Selector -384  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=consumer, groupId=DemoConsumer] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483646
[framework] 2020-06-22 08:51:50,834 - org.apache.kafka.clients.NetworkClient -384  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed connection to node 2147483646. Fetching API versions.
[framework] 2020-06-22 08:51:50,834 - org.apache.kafka.clients.NetworkClient -384  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed connection to node 2147483646. Fetching API versions.
[framework] 2020-06-22 08:51:50,834 - org.apache.kafka.clients.NetworkClient -384  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Initiating API versions fetch from node 2147483646.
[framework] 2020-06-22 08:51:50,834 - org.apache.kafka.clients.NetworkClient -384  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Initiating API versions fetch from node 2147483646.
[framework] 2020-06-22 08:51:50,838 - org.apache.kafka.clients.NetworkClient -388  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-22 08:51:50,838 - org.apache.kafka.clients.NetworkClient -388  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Recorded API versions for node 2147483646: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-22 08:51:50,841 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -391  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Disabling heartbeat thread
[framework] 2020-06-22 08:51:50,841 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -391  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] (Re-)joining group
[framework] 2020-06-22 08:51:50,841 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -391  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Disabling heartbeat thread
[framework] 2020-06-22 08:51:50,842 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -392  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Joining group with current subscription: [topic1]
[framework] 2020-06-22 08:51:50,842 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -392  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] (Re-)joining group
[framework] 2020-06-22 08:51:50,842 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -392  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Joining group with current subscription: [topic1]
[framework] 2020-06-22 08:51:50,842 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -392  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending JoinGroup (JoinGroupRequestData(groupId='DemoConsumer', sessionTimeoutMs=30000, rebalanceTimeoutMs=300000, memberId='consumer-310df908-026f-4f5f-8b36-08e1caa62cd8', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 116, 111, 112, 105, 99, 49, 0, 0, 0, 0])])) to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:51:50,842 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -392  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending JoinGroup (JoinGroupRequestData(groupId='DemoConsumer', sessionTimeoutMs=30000, rebalanceTimeoutMs=300000, memberId='consumer-0bcf4c6e-252b-4887-9aa6-310005ccf646', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 116, 111, 112, 105, 99, 49, 0, 0, 0, 0])])) to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:51:50,845 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -395  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Received successful JoinGroup response: JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=53, protocolName='range', leader='consumer-310df908-026f-4f5f-8b36-08e1caa62cd8', memberId='consumer-0bcf4c6e-252b-4887-9aa6-310005ccf646', members=[])
[framework] 2020-06-22 08:51:50,846 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -396  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending follower SyncGroup to coordinator Kafka-1:9092 (id: 2147483646 rack: null): SyncGroupRequestData(groupId='DemoConsumer', generationId=53, memberId='consumer-0bcf4c6e-252b-4887-9aa6-310005ccf646', groupInstanceId='null', assignments=[])
[framework] 2020-06-22 08:51:50,846 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -396  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Received successful JoinGroup response: JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=53, protocolName='range', leader='consumer-310df908-026f-4f5f-8b36-08e1caa62cd8', memberId='consumer-310df908-026f-4f5f-8b36-08e1caa62cd8', members=[JoinGroupResponseMember(memberId='consumer-0bcf4c6e-252b-4887-9aa6-310005ccf646', groupInstanceId='null', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 116, 111, 112, 105, 99, 49, 0, 0, 0, 0]), JoinGroupResponseMember(memberId='consumer-310df908-026f-4f5f-8b36-08e1caa62cd8', groupInstanceId='null', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 116, 111, 112, 105, 99, 49, 0, 0, 0, 0])])
[framework] 2020-06-22 08:51:50,846 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -396  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Performing assignment using strategy range with subscriptions {consumer-0bcf4c6e-252b-4887-9aa6-310005ccf646=Subscription(topics=[topic1]), consumer-310df908-026f-4f5f-8b36-08e1caa62cd8=Subscription(topics=[topic1])}
[framework] 2020-06-22 08:51:50,847 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -397  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Finished assignment for group: {consumer-0bcf4c6e-252b-4887-9aa6-310005ccf646=Assignment(partitions=[topic1-0, topic1-1]), consumer-310df908-026f-4f5f-8b36-08e1caa62cd8=Assignment(partitions=[topic1-2])}
[framework] 2020-06-22 08:51:50,849 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -399  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending leader SyncGroup to coordinator Kafka-1:9092 (id: 2147483646 rack: null): SyncGroupRequestData(groupId='DemoConsumer', generationId=53, memberId='consumer-310df908-026f-4f5f-8b36-08e1caa62cd8', groupInstanceId='null', assignments=[SyncGroupRequestAssignment(memberId='consumer-0bcf4c6e-252b-4887-9aa6-310005ccf646', assignment=[0, 0, 0, 0, 0, 1, 0, 6, 116, 111, 112, 105, 99, 49, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), SyncGroupRequestAssignment(memberId='consumer-310df908-026f-4f5f-8b36-08e1caa62cd8', assignment=[0, 0, 0, 0, 0, 1, 0, 6, 116, 111, 112, 105, 99, 49, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0])])
[framework] 2020-06-22 08:51:50,852 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -402  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Successfully joined group with generation 53
[framework] 2020-06-22 08:51:50,852 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -402  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Successfully joined group with generation 53
[framework] 2020-06-22 08:51:50,852 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -402  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Enabling heartbeat thread
[framework] 2020-06-22 08:51:50,852 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -402  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Enabling heartbeat thread
[framework] 2020-06-22 08:51:50,856 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -406  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Setting newly assigned partitions: topic1-2
[framework] 2020-06-22 08:51:50,856 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -406  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Setting newly assigned partitions: topic1-1, topic1-0
[framework] 2020-06-22 08:51:50,865 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -415  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetching committed offsets for partitions: [topic1-1, topic1-0]
[framework] 2020-06-22 08:51:50,865 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -415  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetching committed offsets for partitions: [topic1-2]
[framework] 2020-06-22 08:51:50,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -419  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Setting offset for partition topic1-1 to the committed offset FetchPosition{offset=65153, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}}
[framework] 2020-06-22 08:51:50,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -419  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Setting offset for partition topic1-2 to the committed offset FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}}
[framework] 2020-06-22 08:51:50,871 - org.apache.kafka.clients.Metadata -421  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer, groupId=DemoConsumer] Not replacing existing epoch 0 with new epoch 0
[framework] 2020-06-22 08:51:50,871 - org.apache.kafka.clients.Metadata -421  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer, groupId=DemoConsumer] Not replacing existing epoch 0 with new epoch 0
[framework] 2020-06-22 08:51:50,871 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -421  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Setting offset for partition topic1-0 to the committed offset FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}}
[framework] 2020-06-22 08:51:50,871 - org.apache.kafka.clients.Metadata -421  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.Metadata  - [Consumer clientId=consumer, groupId=DemoConsumer] Not replacing existing epoch 0 with new epoch 0
[framework] 2020-06-22 08:51:50,874 - org.apache.kafka.clients.NetworkClient -424  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Initiating connection to node Kafka-1:9092 (id: 1 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-22 08:51:50,874 - org.apache.kafka.clients.NetworkClient -424  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Initiating connection to node Kafka-1:9092 (id: 1 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-22 08:51:50,877 - org.apache.kafka.common.metrics.Metrics -427  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-sent
[framework] 2020-06-22 08:51:50,877 - org.apache.kafka.common.metrics.Metrics -427  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-sent
[framework] 2020-06-22 08:51:50,878 - org.apache.kafka.common.metrics.Metrics -428  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-received
[framework] 2020-06-22 08:51:50,878 - org.apache.kafka.common.metrics.Metrics -428  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-received
[framework] 2020-06-22 08:51:50,879 - org.apache.kafka.common.metrics.Metrics -429  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.latency
[framework] 2020-06-22 08:51:50,879 - org.apache.kafka.common.metrics.Metrics -429  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.latency
[framework] 2020-06-22 08:51:50,879 - org.apache.kafka.common.network.Selector -429  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=consumer, groupId=DemoConsumer] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 1
[framework] 2020-06-22 08:51:50,879 - org.apache.kafka.common.network.Selector -429  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.network.Selector  - [Consumer clientId=consumer, groupId=DemoConsumer] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 1
[framework] 2020-06-22 08:51:50,879 - org.apache.kafka.clients.NetworkClient -429  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed connection to node 1. Fetching API versions.
[framework] 2020-06-22 08:51:50,879 - org.apache.kafka.clients.NetworkClient -429  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed connection to node 1. Fetching API versions.
[framework] 2020-06-22 08:51:50,879 - org.apache.kafka.clients.NetworkClient -429  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Initiating API versions fetch from node 1.
[framework] 2020-06-22 08:51:50,879 - org.apache.kafka.clients.NetworkClient -429  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Initiating API versions fetch from node 1.
[framework] 2020-06-22 08:51:50,882 - org.apache.kafka.clients.NetworkClient -432  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-22 08:51:50,883 - org.apache.kafka.clients.NetworkClient -433  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.NetworkClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-22 08:51:50,889 - org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient -439  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Handling OffsetsForLeaderEpoch response for topic1-1. Got offset 65154 for epoch 0
[framework] 2020-06-22 08:51:50,889 - org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient -439  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Handling OffsetsForLeaderEpoch response for topic1-2. Got offset 62091 for epoch 0
[framework] 2020-06-22 08:51:50,889 - org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient -439  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient  - [Consumer clientId=consumer, groupId=DemoConsumer] Handling OffsetsForLeaderEpoch response for topic1-0. Got offset 62129 for epoch 0
[framework] 2020-06-22 08:51:50,894 - org.apache.kafka.clients.consumer.internals.Fetcher -444  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65153, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:50,894 - org.apache.kafka.clients.consumer.internals.Fetcher -444  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:50,894 - org.apache.kafka.clients.consumer.internals.Fetcher -444  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:50,894 - org.apache.kafka.clients.FetchSessionHandler -444  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 1 with 2 partition(s).
[framework] 2020-06-22 08:51:50,894 - org.apache.kafka.clients.FetchSessionHandler -444  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 1 with 1 partition(s).
[framework] 2020-06-22 08:51:50,895 - org.apache.kafka.clients.consumer.internals.Fetcher -445  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED FullFetchRequest(topic1-1, topic1-0) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:50,895 - org.apache.kafka.clients.consumer.internals.Fetcher -445  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED FullFetchRequest(topic1-2) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:50,905 - org.apache.kafka.clients.FetchSessionHandler -455  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent a full fetch response that created a new incremental fetch session 796767364 with 2 response partition(s)
[framework] 2020-06-22 08:51:50,906 - org.apache.kafka.clients.consumer.internals.Fetcher -456  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65153 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65154, lastStableOffset = 65154, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=82)
[framework] 2020-06-22 08:51:50,907 - org.apache.kafka.clients.consumer.internals.Fetcher -457  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 62129 for partition topic1-0 returned fetch data (error=NONE, highWaterMark=62129, lastStableOffset = 62129, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=0)
[framework] 2020-06-22 08:51:50,917 - org.apache.kafka.common.metrics.Metrics -467  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic1-1.records-lag
[framework] 2020-06-22 08:51:50,918 - org.apache.kafka.common.metrics.Metrics -468  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic1-1.records-lead
[framework] 2020-06-22 08:51:50,919 - org.apache.kafka.common.metrics.Metrics -469  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.bytes-fetched
[framework] 2020-06-22 08:51:50,919 - org.apache.kafka.common.metrics.Metrics -469  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.records-fetched
[framework] 2020-06-22 08:51:50,919 - org.apache.kafka.common.metrics.Metrics -469  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic1-0.records-lag
[framework] 2020-06-22 08:51:50,920 - org.apache.kafka.common.metrics.Metrics -470  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic1-0.records-lead
[framework] 2020-06-22 08:51:50,920 - org.apache.kafka.clients.consumer.internals.Fetcher -470  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:50,920 - org.apache.kafka.clients.consumer.internals.Fetcher -470  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65154, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:50,921 - org.apache.kafka.clients.FetchSessionHandler -471  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=1) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:50,921 - org.apache.kafka.clients.consumer.internals.Fetcher -471  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:50,923 - org.apache.kafka.clients.consumer.KafkaConsumer -473  [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:51,401 - org.apache.kafka.clients.FetchSessionHandler -951  [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent a full fetch response that created a new incremental fetch session 1067249966 with 1 response partition(s)
[framework] 2020-06-22 08:51:51,401 - org.apache.kafka.clients.consumer.internals.Fetcher -951  [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 62091 for partition topic1-2 returned fetch data (error=NONE, highWaterMark=62091, lastStableOffset = 62091, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=0)
[framework] 2020-06-22 08:51:51,401 - org.apache.kafka.common.metrics.Metrics -951  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.bytes-fetched
[framework] 2020-06-22 08:51:51,402 - org.apache.kafka.common.metrics.Metrics -952  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.records-fetched
[framework] 2020-06-22 08:51:51,402 - org.apache.kafka.common.metrics.Metrics -952  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic1-2.records-lag
[framework] 2020-06-22 08:51:51,402 - org.apache.kafka.common.metrics.Metrics -952  [KafkaConsumerExample_name] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic1-2.records-lead
[framework] 2020-06-22 08:51:51,403 - org.apache.kafka.clients.consumer.internals.Fetcher -953  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:51,403 - org.apache.kafka.clients.FetchSessionHandler -953  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=1) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:51,403 - org.apache.kafka.clients.consumer.internals.Fetcher -953  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:51,426 - org.apache.kafka.clients.FetchSessionHandler -976  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:51:51,426 - org.apache.kafka.clients.consumer.internals.Fetcher -976  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:51,426 - org.apache.kafka.clients.consumer.internals.Fetcher -976  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65154, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:51,426 - org.apache.kafka.clients.FetchSessionHandler -976  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=2) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:51,427 - org.apache.kafka.clients.consumer.internals.Fetcher -977  [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:51,614 - org.apache.kafka.clients.NetworkClient -1164 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initialize connection to node Kafka-1:9093 (id: 2 rack: null) for sending metadata request
[framework] 2020-06-22 08:51:51,614 - org.apache.kafka.clients.NetworkClient -1164 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating connection to node Kafka-1:9093 (id: 2 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-22 08:51:51,617 - org.apache.kafka.common.metrics.Metrics -1167 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2.bytes-sent
[framework] 2020-06-22 08:51:51,618 - org.apache.kafka.common.metrics.Metrics -1168 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2.bytes-received
[framework] 2020-06-22 08:51:51,619 - org.apache.kafka.common.metrics.Metrics -1169 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-2.latency
[framework] 2020-06-22 08:51:51,619 - org.apache.kafka.common.network.Selector -1169 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.network.Selector  - [Producer clientId=DemoProducer] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2
[framework] 2020-06-22 08:51:51,619 - org.apache.kafka.clients.NetworkClient -1169 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Completed connection to node 2. Fetching API versions.
[framework] 2020-06-22 08:51:51,619 - org.apache.kafka.clients.NetworkClient -1169 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating API versions fetch from node 2.
[framework] 2020-06-22 08:51:51,623 - org.apache.kafka.clients.NetworkClient -1173 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Recorded API versions for node 2: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-22 08:51:51,623 - org.apache.kafka.clients.NetworkClient -1173 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='topic1')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node Kafka-1:9093 (id: 2 rack: null)
[framework] 2020-06-22 08:51:51,630 - org.apache.kafka.clients.Metadata -1180 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updating last seen epoch from null to 0 for partition topic1-0
[framework] 2020-06-22 08:51:51,630 - org.apache.kafka.clients.Metadata -1180 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updating last seen epoch from null to 0 for partition topic1-2
[framework] 2020-06-22 08:51:51,630 - org.apache.kafka.clients.Metadata -1180 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updating last seen epoch from null to 0 for partition topic1-1
[framework] 2020-06-22 08:51:51,631 - org.apache.kafka.clients.Metadata -1181 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.Metadata  - [Producer clientId=DemoProducer] Updated cluster metadata updateVersion 3 to MetadataCache{cluster=Cluster(id = MT1saCQCQj6WuKonjf5obA, nodes = [Kafka-1:9093 (id: 2 rack: null), Kafka-1:9092 (id: 1 rack: null)], partitions = [Partition(topic = topic1, partition = 1, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = topic1, partition = 0, leader = 1, replicas = [1], isr = [1], offlineReplicas = []), Partition(topic = topic1, partition = 2, leader = 1, replicas = [1], isr = [1], offlineReplicas = [])], controller = Kafka-1:9092 (id: 1 rack: null))}
[framework] 2020-06-22 08:51:51,726 - org.apache.kafka.clients.consumer.KafkaConsumer -1276 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:51,857 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -1407 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:51,857 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -1407 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65154, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:51,865 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -1415 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62091 for partition topic1-2
[framework] 2020-06-22 08:51:51,865 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -1415 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 65154 for partition topic1-1
[framework] 2020-06-22 08:51:51,865 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -1415 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62129 for partition topic1-0
[framework] 2020-06-22 08:51:51,866 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -1416 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:51,866 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -1416 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65154, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:51,908 - org.apache.kafka.clients.FetchSessionHandler -1458 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:51,908 - org.apache.kafka.clients.consumer.internals.Fetcher -1458 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:51,909 - org.apache.kafka.clients.FetchSessionHandler -1459 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=2) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:51,909 - org.apache.kafka.clients.consumer.internals.Fetcher -1459 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:51,924 - org.apache.kafka.clients.consumer.KafkaConsumer -1474 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:51,931 - org.apache.kafka.clients.FetchSessionHandler -1481 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:51:51,932 - org.apache.kafka.clients.consumer.internals.Fetcher -1482 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:51,932 - org.apache.kafka.clients.consumer.internals.Fetcher -1482 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65154, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:51,932 - org.apache.kafka.clients.FetchSessionHandler -1482 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=3) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:51,932 - org.apache.kafka.clients.consumer.internals.Fetcher -1482 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:52,136 - org.apache.kafka.clients.NetworkClient -1686 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating connection to node Kafka-1:9092 (id: 1 rack: null) using address kafka-1/47.110.251.155
[framework] 2020-06-22 08:51:52,138 - org.apache.kafka.common.metrics.Metrics -1688 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-sent
[framework] 2020-06-22 08:51:52,139 - org.apache.kafka.common.metrics.Metrics -1689 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.bytes-received
[framework] 2020-06-22 08:51:52,139 - org.apache.kafka.common.metrics.Metrics -1689 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name node-1.latency
[framework] 2020-06-22 08:51:52,139 - org.apache.kafka.common.network.Selector -1689 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.network.Selector  - [Producer clientId=DemoProducer] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 1
[framework] 2020-06-22 08:51:52,139 - org.apache.kafka.clients.NetworkClient -1689 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Completed connection to node 1. Fetching API versions.
[framework] 2020-06-22 08:51:52,139 - org.apache.kafka.clients.NetworkClient -1689 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Initiating API versions fetch from node 1.
[framework] 2020-06-22 08:51:52,142 - org.apache.kafka.clients.NetworkClient -1692 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.clients.NetworkClient  - [Producer clientId=DemoProducer] Recorded API versions for node 1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[framework] 2020-06-22 08:51:52,142 - org.apache.kafka.common.metrics.Metrics -1692 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.records-per-batch
[framework] 2020-06-22 08:51:52,142 - org.apache.kafka.common.metrics.Metrics -1692 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.bytes
[framework] 2020-06-22 08:51:52,142 - org.apache.kafka.common.metrics.Metrics -1692 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.compression-rate
[framework] 2020-06-22 08:51:52,142 - org.apache.kafka.common.metrics.Metrics -1692 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.record-retries
[framework] 2020-06-22 08:51:52,143 - org.apache.kafka.common.metrics.Metrics -1693 [kafka-producer-network-thread | DemoProducer] DEBUG org.apache.kafka.common.metrics.Metrics  - Added sensor with name topic.topic1.record-errors
[framework] 2020-06-22 08:51:52,147 - org.apache.kafka.clients.FetchSessionHandler -1697 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 1 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:52,147 - org.apache.kafka.clients.consumer.internals.Fetcher -1697 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65154 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65155, lastStableOffset = 65155, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=81)
[framework] 2020-06-22 08:51:52,147 - org.apache.kafka.clients.consumer.internals.Fetcher -1697 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:52,147 - org.apache.kafka.clients.consumer.internals.Fetcher -1697 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65155, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:52,147 - org.apache.kafka.clients.FetchSessionHandler -1697 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=4) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:52,147 - org.apache.kafka.clients.consumer.internals.Fetcher -1697 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:52,148 - org.apache.kafka.clients.consumer.KafkaConsumer -1698 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:52,414 - org.apache.kafka.clients.FetchSessionHandler -1964 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:52,415 - org.apache.kafka.clients.consumer.internals.Fetcher -1965 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:52,415 - org.apache.kafka.clients.FetchSessionHandler -1965 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=3) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:52,415 - org.apache.kafka.clients.consumer.internals.Fetcher -1965 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:52,651 - org.apache.kafka.clients.FetchSessionHandler -2201 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:51:52,652 - org.apache.kafka.clients.consumer.internals.Fetcher -2202 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:52,652 - org.apache.kafka.clients.consumer.internals.Fetcher -2202 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65155, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:52,652 - org.apache.kafka.clients.FetchSessionHandler -2202 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=5) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:52,653 - org.apache.kafka.clients.consumer.internals.Fetcher -2203 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:52,728 - org.apache.kafka.clients.consumer.KafkaConsumer -2278 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:52,858 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -2408 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65155, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:52,858 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -2408 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:52,863 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -2413 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 65155 for partition topic1-1
[framework] 2020-06-22 08:51:52,863 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -2413 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62091 for partition topic1-2
[framework] 2020-06-22 08:51:52,863 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -2413 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62129 for partition topic1-0
[framework] 2020-06-22 08:51:52,864 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -2414 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:52,864 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -2414 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65155, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:52,920 - org.apache.kafka.clients.FetchSessionHandler -2470 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:52,921 - org.apache.kafka.clients.consumer.internals.Fetcher -2471 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:52,922 - org.apache.kafka.clients.FetchSessionHandler -2472 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=4) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:52,922 - org.apache.kafka.clients.consumer.internals.Fetcher -2472 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:53,145 - org.apache.kafka.clients.FetchSessionHandler -2695 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 1 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:53,146 - org.apache.kafka.clients.consumer.internals.Fetcher -2696 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65155 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65156, lastStableOffset = 65156, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=81)
[framework] 2020-06-22 08:51:53,147 - org.apache.kafka.clients.consumer.internals.Fetcher -2697 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:53,147 - org.apache.kafka.clients.consumer.internals.Fetcher -2697 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65156, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:53,148 - org.apache.kafka.clients.FetchSessionHandler -2698 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=6) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:53,148 - org.apache.kafka.clients.consumer.internals.Fetcher -2698 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:53,150 - org.apache.kafka.clients.consumer.KafkaConsumer -2700 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:53,426 - org.apache.kafka.clients.FetchSessionHandler -2976 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:53,427 - org.apache.kafka.clients.consumer.internals.Fetcher -2977 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:53,427 - org.apache.kafka.clients.FetchSessionHandler -2977 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=5) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:53,427 - org.apache.kafka.clients.consumer.internals.Fetcher -2977 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:53,653 - org.apache.kafka.clients.FetchSessionHandler -3203 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:51:53,654 - org.apache.kafka.clients.consumer.internals.Fetcher -3204 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:53,655 - org.apache.kafka.clients.consumer.internals.Fetcher -3205 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65156, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:53,655 - org.apache.kafka.clients.FetchSessionHandler -3205 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=7) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:53,655 - org.apache.kafka.clients.consumer.internals.Fetcher -3205 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:53,729 - org.apache.kafka.clients.consumer.KafkaConsumer -3279 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:53,853 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -3403 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending Heartbeat request to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:51:53,853 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -3403 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending Heartbeat request to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:51:53,862 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -3412 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:53,863 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -3413 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65156, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:53,869 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -3419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Received successful Heartbeat response
[framework] 2020-06-22 08:51:53,869 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -3419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Received successful Heartbeat response
[framework] 2020-06-22 08:51:53,870 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -3420 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62091 for partition topic1-2
[framework] 2020-06-22 08:51:53,870 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -3420 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:53,871 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -3421 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 65156 for partition topic1-1
[framework] 2020-06-22 08:51:53,871 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -3421 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62129 for partition topic1-0
[framework] 2020-06-22 08:51:53,871 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -3421 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65156, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:53,932 - org.apache.kafka.clients.FetchSessionHandler -3482 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:53,933 - org.apache.kafka.clients.consumer.internals.Fetcher -3483 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:53,934 - org.apache.kafka.clients.FetchSessionHandler -3484 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=6) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:53,934 - org.apache.kafka.clients.consumer.internals.Fetcher -3484 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:54,147 - org.apache.kafka.clients.FetchSessionHandler -3697 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 1 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:54,147 - org.apache.kafka.clients.consumer.internals.Fetcher -3697 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65156 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65157, lastStableOffset = 65157, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=81)
[framework] 2020-06-22 08:51:54,148 - org.apache.kafka.clients.consumer.internals.Fetcher -3698 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:54,149 - org.apache.kafka.clients.consumer.internals.Fetcher -3699 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65157, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:54,149 - org.apache.kafka.clients.FetchSessionHandler -3699 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=8) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:54,149 - org.apache.kafka.clients.consumer.internals.Fetcher -3699 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:54,150 - org.apache.kafka.clients.consumer.KafkaConsumer -3700 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:54,438 - org.apache.kafka.clients.FetchSessionHandler -3988 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:54,439 - org.apache.kafka.clients.consumer.internals.Fetcher -3989 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:54,439 - org.apache.kafka.clients.FetchSessionHandler -3989 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=7) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:54,439 - org.apache.kafka.clients.consumer.internals.Fetcher -3989 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:54,654 - org.apache.kafka.clients.FetchSessionHandler -4204 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:51:54,655 - org.apache.kafka.clients.consumer.internals.Fetcher -4205 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:54,655 - org.apache.kafka.clients.consumer.internals.Fetcher -4205 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65157, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:54,656 - org.apache.kafka.clients.FetchSessionHandler -4206 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=9) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:54,656 - org.apache.kafka.clients.consumer.internals.Fetcher -4206 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:54,732 - org.apache.kafka.clients.consumer.KafkaConsumer -4282 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:54,864 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -4414 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:54,865 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -4415 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65157, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:54,868 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -4418 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62091 for partition topic1-2
[framework] 2020-06-22 08:51:54,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -4419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 65157 for partition topic1-1
[framework] 2020-06-22 08:51:54,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -4419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62129 for partition topic1-0
[framework] 2020-06-22 08:51:54,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -4419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:54,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -4419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65157, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:54,944 - org.apache.kafka.clients.FetchSessionHandler -4494 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:54,945 - org.apache.kafka.clients.consumer.internals.Fetcher -4495 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:54,946 - org.apache.kafka.clients.FetchSessionHandler -4496 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=8) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:54,946 - org.apache.kafka.clients.consumer.internals.Fetcher -4496 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:55,148 - org.apache.kafka.clients.FetchSessionHandler -4698 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 1 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:55,148 - org.apache.kafka.clients.consumer.internals.Fetcher -4698 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65157 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65158, lastStableOffset = 65158, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=81)
[framework] 2020-06-22 08:51:55,149 - org.apache.kafka.clients.consumer.internals.Fetcher -4699 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:55,150 - org.apache.kafka.clients.consumer.internals.Fetcher -4700 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65158, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:55,150 - org.apache.kafka.clients.FetchSessionHandler -4700 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=10) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:55,150 - org.apache.kafka.clients.consumer.internals.Fetcher -4700 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:55,151 - org.apache.kafka.clients.consumer.KafkaConsumer -4701 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:55,450 - org.apache.kafka.clients.FetchSessionHandler -5000 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:55,451 - org.apache.kafka.clients.consumer.internals.Fetcher -5001 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:55,451 - org.apache.kafka.clients.FetchSessionHandler -5001 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=9) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:55,451 - org.apache.kafka.clients.consumer.internals.Fetcher -5001 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:55,656 - org.apache.kafka.clients.FetchSessionHandler -5206 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:51:55,657 - org.apache.kafka.clients.consumer.internals.Fetcher -5207 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:55,657 - org.apache.kafka.clients.consumer.internals.Fetcher -5207 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65158, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:55,657 - org.apache.kafka.clients.FetchSessionHandler -5207 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=11) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:55,658 - org.apache.kafka.clients.consumer.internals.Fetcher -5208 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:55,734 - org.apache.kafka.clients.consumer.KafkaConsumer -5284 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:55,864 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5414 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:55,865 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5415 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65158, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:55,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62091 for partition topic1-2
[framework] 2020-06-22 08:51:55,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 65158 for partition topic1-1
[framework] 2020-06-22 08:51:55,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62129 for partition topic1-0
[framework] 2020-06-22 08:51:55,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:55,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -5419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65158, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:55,956 - org.apache.kafka.clients.FetchSessionHandler -5506 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:55,957 - org.apache.kafka.clients.consumer.internals.Fetcher -5507 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:55,957 - org.apache.kafka.clients.FetchSessionHandler -5507 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=10) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:55,958 - org.apache.kafka.clients.consumer.internals.Fetcher -5508 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:56,148 - org.apache.kafka.clients.FetchSessionHandler -5698 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 1 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:56,148 - org.apache.kafka.clients.consumer.internals.Fetcher -5698 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65158 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65159, lastStableOffset = 65159, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=81)
[framework] 2020-06-22 08:51:56,149 - org.apache.kafka.clients.consumer.internals.Fetcher -5699 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:56,149 - org.apache.kafka.clients.consumer.internals.Fetcher -5699 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65159, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:56,149 - org.apache.kafka.clients.FetchSessionHandler -5699 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=12) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:56,150 - org.apache.kafka.clients.consumer.internals.Fetcher -5700 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:56,151 - org.apache.kafka.clients.consumer.KafkaConsumer -5701 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:56,462 - org.apache.kafka.clients.FetchSessionHandler -6012 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:56,463 - org.apache.kafka.clients.consumer.internals.Fetcher -6013 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:56,463 - org.apache.kafka.clients.FetchSessionHandler -6013 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=11) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:56,464 - org.apache.kafka.clients.consumer.internals.Fetcher -6014 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:56,654 - org.apache.kafka.clients.FetchSessionHandler -6204 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:51:56,655 - org.apache.kafka.clients.consumer.internals.Fetcher -6205 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:56,655 - org.apache.kafka.clients.consumer.internals.Fetcher -6205 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65159, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:56,656 - org.apache.kafka.clients.FetchSessionHandler -6206 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=13) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:56,656 - org.apache.kafka.clients.consumer.internals.Fetcher -6206 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:56,736 - org.apache.kafka.clients.consumer.KafkaConsumer -6286 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:56,854 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -6404 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending Heartbeat request to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:51:56,854 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -6404 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending Heartbeat request to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:51:56,858 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -6408 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Received successful Heartbeat response
[framework] 2020-06-22 08:51:56,858 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -6408 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Received successful Heartbeat response
[framework] 2020-06-22 08:51:56,865 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -6415 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65159, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:56,865 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -6415 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:56,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -6419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 65159 for partition topic1-1
[framework] 2020-06-22 08:51:56,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -6419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62091 for partition topic1-2
[framework] 2020-06-22 08:51:56,870 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -6420 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62129 for partition topic1-0
[framework] 2020-06-22 08:51:56,870 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -6420 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:56,870 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -6420 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65159, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:56,968 - org.apache.kafka.clients.FetchSessionHandler -6518 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:56,969 - org.apache.kafka.clients.consumer.internals.Fetcher -6519 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:56,969 - org.apache.kafka.clients.FetchSessionHandler -6519 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=12) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:56,969 - org.apache.kafka.clients.consumer.internals.Fetcher -6519 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:57,148 - org.apache.kafka.clients.FetchSessionHandler -6698 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 1 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:57,148 - org.apache.kafka.clients.consumer.internals.Fetcher -6698 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65159 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65160, lastStableOffset = 65160, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=81)
[framework] 2020-06-22 08:51:57,149 - org.apache.kafka.clients.consumer.internals.Fetcher -6699 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:57,149 - org.apache.kafka.clients.consumer.internals.Fetcher -6699 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65160, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:57,149 - org.apache.kafka.clients.FetchSessionHandler -6699 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=14) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:57,150 - org.apache.kafka.clients.consumer.internals.Fetcher -6700 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:57,151 - org.apache.kafka.clients.consumer.KafkaConsumer -6701 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:57,474 - org.apache.kafka.clients.FetchSessionHandler -7024 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:57,475 - org.apache.kafka.clients.consumer.internals.Fetcher -7025 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:57,476 - org.apache.kafka.clients.FetchSessionHandler -7026 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=13) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:57,476 - org.apache.kafka.clients.consumer.internals.Fetcher -7026 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:57,654 - org.apache.kafka.clients.FetchSessionHandler -7204 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:51:57,655 - org.apache.kafka.clients.consumer.internals.Fetcher -7205 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:57,655 - org.apache.kafka.clients.consumer.internals.Fetcher -7205 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65160, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:57,655 - org.apache.kafka.clients.FetchSessionHandler -7205 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=15) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:57,655 - org.apache.kafka.clients.consumer.internals.Fetcher -7205 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:57,738 - org.apache.kafka.clients.consumer.KafkaConsumer -7288 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:57,866 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -7416 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65160, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:57,866 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -7416 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:57,870 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -7420 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 65160 for partition topic1-1
[framework] 2020-06-22 08:51:57,870 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -7420 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62129 for partition topic1-0
[framework] 2020-06-22 08:51:57,870 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -7420 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62091 for partition topic1-2
[framework] 2020-06-22 08:51:57,871 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -7421 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65160, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:57,871 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -7421 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:57,991 - org.apache.kafka.clients.FetchSessionHandler -7541 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:57,992 - org.apache.kafka.clients.consumer.internals.Fetcher -7542 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:57,992 - org.apache.kafka.clients.FetchSessionHandler -7542 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=14) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:57,993 - org.apache.kafka.clients.consumer.internals.Fetcher -7543 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:58,150 - org.apache.kafka.clients.FetchSessionHandler -7700 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 1 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:58,150 - org.apache.kafka.clients.consumer.internals.Fetcher -7700 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65160 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65161, lastStableOffset = 65161, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=81)
[framework] 2020-06-22 08:51:58,151 - org.apache.kafka.clients.consumer.internals.Fetcher -7701 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:58,151 - org.apache.kafka.clients.consumer.internals.Fetcher -7701 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65161, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:58,152 - org.apache.kafka.clients.FetchSessionHandler -7702 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=16) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:58,152 - org.apache.kafka.clients.consumer.internals.Fetcher -7702 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:58,153 - org.apache.kafka.clients.consumer.KafkaConsumer -7703 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:58,497 - org.apache.kafka.clients.FetchSessionHandler -8047 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:58,498 - org.apache.kafka.clients.consumer.internals.Fetcher -8048 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:58,498 - org.apache.kafka.clients.FetchSessionHandler -8048 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=15) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:58,498 - org.apache.kafka.clients.consumer.internals.Fetcher -8048 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:58,656 - org.apache.kafka.clients.FetchSessionHandler -8206 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:51:58,657 - org.apache.kafka.clients.consumer.internals.Fetcher -8207 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:58,657 - org.apache.kafka.clients.consumer.internals.Fetcher -8207 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65161, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:58,657 - org.apache.kafka.clients.FetchSessionHandler -8207 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=17) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:58,657 - org.apache.kafka.clients.consumer.internals.Fetcher -8207 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:58,741 - org.apache.kafka.clients.consumer.KafkaConsumer -8291 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:58,866 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -8416 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:58,866 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -8416 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65161, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:58,871 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -8421 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 65161 for partition topic1-1
[framework] 2020-06-22 08:51:58,871 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -8421 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62129 for partition topic1-0
[framework] 2020-06-22 08:51:58,871 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -8421 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62091 for partition topic1-2
[framework] 2020-06-22 08:51:58,871 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -8421 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65161, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:58,871 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -8421 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:59,004 - org.apache.kafka.clients.FetchSessionHandler -8554 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:59,005 - org.apache.kafka.clients.consumer.internals.Fetcher -8555 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:59,006 - org.apache.kafka.clients.FetchSessionHandler -8556 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=16) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:59,006 - org.apache.kafka.clients.consumer.internals.Fetcher -8556 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:59,150 - org.apache.kafka.clients.FetchSessionHandler -8700 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 1 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:59,151 - org.apache.kafka.clients.consumer.internals.Fetcher -8701 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65161 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65162, lastStableOffset = 65162, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=81)
[framework] 2020-06-22 08:51:59,151 - org.apache.kafka.clients.consumer.internals.Fetcher -8701 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:59,152 - org.apache.kafka.clients.consumer.internals.Fetcher -8702 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65162, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:59,152 - org.apache.kafka.clients.FetchSessionHandler -8702 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=18) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:59,152 - org.apache.kafka.clients.consumer.internals.Fetcher -8702 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:59,153 - org.apache.kafka.clients.consumer.KafkaConsumer -8703 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:59,527 - org.apache.kafka.clients.FetchSessionHandler -9077 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:51:59,528 - org.apache.kafka.clients.consumer.internals.Fetcher -9078 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:59,528 - org.apache.kafka.clients.FetchSessionHandler -9078 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=17) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:51:59,528 - org.apache.kafka.clients.consumer.internals.Fetcher -9078 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:59,657 - org.apache.kafka.clients.FetchSessionHandler -9207 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:51:59,658 - org.apache.kafka.clients.consumer.internals.Fetcher -9208 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:59,658 - org.apache.kafka.clients.consumer.internals.Fetcher -9208 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65162, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:59,658 - org.apache.kafka.clients.FetchSessionHandler -9208 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=19) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:51:59,658 - org.apache.kafka.clients.consumer.internals.Fetcher -9208 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:51:59,743 - org.apache.kafka.clients.consumer.KafkaConsumer -9293 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:51:59,855 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -9405 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending Heartbeat request to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:51:59,855 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -9405 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending Heartbeat request to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:51:59,868 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -9418 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:59,870 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -9420 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Received successful Heartbeat response
[framework] 2020-06-22 08:51:59,870 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -9420 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Received successful Heartbeat response
[framework] 2020-06-22 08:51:59,870 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -9420 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65162, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:59,872 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -9422 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62091 for partition topic1-2
[framework] 2020-06-22 08:51:59,873 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -9423 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:51:59,873 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -9423 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 65162 for partition topic1-1
[framework] 2020-06-22 08:51:59,873 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -9423 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62129 for partition topic1-0
[framework] 2020-06-22 08:51:59,874 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -9424 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65162, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:00,047 - org.apache.kafka.clients.FetchSessionHandler -9597 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:00,048 - org.apache.kafka.clients.consumer.internals.Fetcher -9598 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:00,048 - org.apache.kafka.clients.FetchSessionHandler -9598 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=18) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:52:00,048 - org.apache.kafka.clients.consumer.internals.Fetcher -9598 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:00,151 - org.apache.kafka.clients.FetchSessionHandler -9701 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 1 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:00,151 - org.apache.kafka.clients.consumer.internals.Fetcher -9701 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65162 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65163, lastStableOffset = 65163, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=81)
[framework] 2020-06-22 08:52:00,152 - org.apache.kafka.clients.consumer.internals.Fetcher -9702 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:00,152 - org.apache.kafka.clients.consumer.internals.Fetcher -9702 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65163, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:00,152 - org.apache.kafka.clients.FetchSessionHandler -9702 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=20) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:52:00,152 - org.apache.kafka.clients.consumer.internals.Fetcher -9702 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:00,153 - org.apache.kafka.clients.consumer.KafkaConsumer -9703 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:52:00,552 - org.apache.kafka.clients.FetchSessionHandler -10102 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:00,553 - org.apache.kafka.clients.consumer.internals.Fetcher -10103 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:00,553 - org.apache.kafka.clients.FetchSessionHandler -10103 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=19) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:52:00,554 - org.apache.kafka.clients.consumer.internals.Fetcher -10104 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:00,656 - org.apache.kafka.clients.FetchSessionHandler -10206 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:52:00,658 - org.apache.kafka.clients.consumer.internals.Fetcher -10208 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:00,658 - org.apache.kafka.clients.consumer.internals.Fetcher -10208 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65163, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:00,658 - org.apache.kafka.clients.FetchSessionHandler -10208 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=21) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:52:00,658 - org.apache.kafka.clients.consumer.internals.Fetcher -10208 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:00,745 - org.apache.kafka.clients.consumer.KafkaConsumer -10295 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:52:00,869 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10419 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:00,872 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10422 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65163, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:00,873 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10423 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62091 for partition topic1-2
[framework] 2020-06-22 08:52:00,874 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10424 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:00,876 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10426 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 65163 for partition topic1-1
[framework] 2020-06-22 08:52:00,876 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10426 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62129 for partition topic1-0
[framework] 2020-06-22 08:52:00,876 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -10426 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65163, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:01,058 - org.apache.kafka.clients.FetchSessionHandler -10608 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:01,059 - org.apache.kafka.clients.consumer.internals.Fetcher -10609 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:01,059 - org.apache.kafka.clients.FetchSessionHandler -10609 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=20) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:52:01,059 - org.apache.kafka.clients.consumer.internals.Fetcher -10609 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:01,151 - org.apache.kafka.clients.FetchSessionHandler -10701 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 1 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:01,151 - org.apache.kafka.clients.consumer.internals.Fetcher -10701 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65163 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65164, lastStableOffset = 65164, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=82)
[framework] 2020-06-22 08:52:01,152 - org.apache.kafka.clients.consumer.internals.Fetcher -10702 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:01,152 - org.apache.kafka.clients.consumer.internals.Fetcher -10702 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65164, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:01,152 - org.apache.kafka.clients.FetchSessionHandler -10702 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=22) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:52:01,152 - org.apache.kafka.clients.consumer.internals.Fetcher -10702 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:01,154 - org.apache.kafka.clients.consumer.KafkaConsumer -10704 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:52:01,564 - org.apache.kafka.clients.FetchSessionHandler -11114 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:01,565 - org.apache.kafka.clients.consumer.internals.Fetcher -11115 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:01,565 - org.apache.kafka.clients.FetchSessionHandler -11115 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=21) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:52:01,565 - org.apache.kafka.clients.consumer.internals.Fetcher -11115 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:01,658 - org.apache.kafka.clients.FetchSessionHandler -11208 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:52:01,658 - org.apache.kafka.clients.consumer.internals.Fetcher -11208 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:01,659 - org.apache.kafka.clients.consumer.internals.Fetcher -11209 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65164, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:01,659 - org.apache.kafka.clients.FetchSessionHandler -11209 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=23) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:52:01,659 - org.apache.kafka.clients.consumer.internals.Fetcher -11209 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:01,746 - org.apache.kafka.clients.consumer.KafkaConsumer -11296 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:52:01,870 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -11420 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:01,871 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -11421 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65164, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:01,873 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -11423 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62091 for partition topic1-2
[framework] 2020-06-22 08:52:01,873 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -11423 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:01,874 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -11424 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 65164 for partition topic1-1
[framework] 2020-06-22 08:52:01,874 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -11424 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62129 for partition topic1-0
[framework] 2020-06-22 08:52:01,874 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -11424 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65164, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:02,069 - org.apache.kafka.clients.FetchSessionHandler -11619 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:02,070 - org.apache.kafka.clients.consumer.internals.Fetcher -11620 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:02,070 - org.apache.kafka.clients.FetchSessionHandler -11620 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=22) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:52:02,070 - org.apache.kafka.clients.consumer.internals.Fetcher -11620 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:02,151 - org.apache.kafka.clients.FetchSessionHandler -11701 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 1 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:02,151 - org.apache.kafka.clients.consumer.internals.Fetcher -11701 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65164 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65165, lastStableOffset = 65165, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=82)
[framework] 2020-06-22 08:52:02,151 - org.apache.kafka.clients.consumer.internals.Fetcher -11701 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:02,151 - org.apache.kafka.clients.consumer.internals.Fetcher -11701 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65165, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:02,151 - org.apache.kafka.clients.FetchSessionHandler -11701 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=24) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:52:02,151 - org.apache.kafka.clients.consumer.internals.Fetcher -11701 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:02,151 - org.apache.kafka.clients.consumer.KafkaConsumer -11701 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:52:02,574 - org.apache.kafka.clients.FetchSessionHandler -12124 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:02,575 - org.apache.kafka.clients.consumer.internals.Fetcher -12125 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:02,575 - org.apache.kafka.clients.FetchSessionHandler -12125 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=23) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:52:02,575 - org.apache.kafka.clients.consumer.internals.Fetcher -12125 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:02,655 - org.apache.kafka.clients.FetchSessionHandler -12205 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:52:02,656 - org.apache.kafka.clients.consumer.internals.Fetcher -12206 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:02,656 - org.apache.kafka.clients.consumer.internals.Fetcher -12206 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65165, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:02,657 - org.apache.kafka.clients.FetchSessionHandler -12207 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=25) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:52:02,657 - org.apache.kafka.clients.consumer.internals.Fetcher -12207 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:02,747 - org.apache.kafka.clients.consumer.KafkaConsumer -12297 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:52:02,856 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -12406 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending Heartbeat request to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:52:02,856 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -12406 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending Heartbeat request to coordinator Kafka-1:9092 (id: 2147483646 rack: null)
[framework] 2020-06-22 08:52:02,859 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -12409 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Received successful Heartbeat response
[framework] 2020-06-22 08:52:02,859 - org.apache.kafka.clients.consumer.internals.AbstractCoordinator -12409 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Received successful Heartbeat response
[framework] 2020-06-22 08:52:02,870 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -12420 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:02,872 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -12422 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65165, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:02,874 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -12424 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62091 for partition topic1-2
[framework] 2020-06-22 08:52:02,874 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -12424 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:02,875 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -12425 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 65165 for partition topic1-1
[framework] 2020-06-22 08:52:02,876 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -12426 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62129 for partition topic1-0
[framework] 2020-06-22 08:52:02,876 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -12426 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65165, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:03,079 - org.apache.kafka.clients.FetchSessionHandler -12629 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:03,079 - org.apache.kafka.clients.consumer.internals.Fetcher -12629 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:03,080 - org.apache.kafka.clients.FetchSessionHandler -12630 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=24) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:52:03,080 - org.apache.kafka.clients.consumer.internals.Fetcher -12630 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:03,153 - org.apache.kafka.clients.FetchSessionHandler -12703 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 1 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:03,153 - org.apache.kafka.clients.consumer.internals.Fetcher -12703 [kafka-coordinator-heartbeat-thread | DemoConsumer] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65165 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65166, lastStableOffset = 65166, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=82)
[framework] 2020-06-22 08:52:03,155 - org.apache.kafka.clients.consumer.internals.Fetcher -12705 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:03,155 - org.apache.kafka.clients.consumer.internals.Fetcher -12705 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65166, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:03,155 - org.apache.kafka.clients.FetchSessionHandler -12705 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=26) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:52:03,155 - org.apache.kafka.clients.consumer.internals.Fetcher -12705 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:03,156 - org.apache.kafka.clients.consumer.KafkaConsumer -12706 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:52:03,585 - org.apache.kafka.clients.FetchSessionHandler -13135 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:03,585 - org.apache.kafka.clients.consumer.internals.Fetcher -13135 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:03,586 - org.apache.kafka.clients.FetchSessionHandler -13136 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=25) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:52:03,586 - org.apache.kafka.clients.consumer.internals.Fetcher -13136 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:03,659 - org.apache.kafka.clients.FetchSessionHandler -13209 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 0 response partition(s), 2 implied partition(s)
[framework] 2020-06-22 08:52:03,660 - org.apache.kafka.clients.consumer.internals.Fetcher -13210 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:03,660 - org.apache.kafka.clients.consumer.internals.Fetcher -13210 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65166, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:03,660 - org.apache.kafka.clients.FetchSessionHandler -13210 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=27) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:52:03,660 - org.apache.kafka.clients.consumer.internals.Fetcher -13210 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-1, topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:03,748 - org.apache.kafka.clients.consumer.KafkaConsumer -13298 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
[framework] 2020-06-22 08:52:03,872 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -13422 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:03,872 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -13422 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65166, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:03,877 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -13427 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62091 for partition topic1-2
[framework] 2020-06-22 08:52:03,877 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -13427 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-2=OffsetAndMetadata{offset=62091, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:03,877 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -13427 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 65166 for partition topic1-1
[framework] 2020-06-22 08:52:03,877 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -13427 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Committed offset 62129 for partition topic1-0
[framework] 2020-06-22 08:52:03,877 - org.apache.kafka.clients.consumer.internals.ConsumerCoordinator -13427 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator  - [Consumer clientId=consumer, groupId=DemoConsumer] Completed asynchronous auto-commit of offsets {topic1-1=OffsetAndMetadata{offset=65166, leaderEpoch=0, metadata=''}, topic1-0=OffsetAndMetadata{offset=62129, leaderEpoch=0, metadata=''}}
[framework] 2020-06-22 08:52:04,091 - org.apache.kafka.clients.FetchSessionHandler -13641 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 1067249966 with 0 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:04,091 - org.apache.kafka.clients.consumer.internals.Fetcher -13641 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-2 at position FetchPosition{offset=62091, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:04,092 - org.apache.kafka.clients.FetchSessionHandler -13642 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=1067249966, epoch=26) for node 1. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
[framework] 2020-06-22 08:52:04,092 - org.apache.kafka.clients.consumer.internals.Fetcher -13642 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(topic1-2)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:04,154 - org.apache.kafka.clients.FetchSessionHandler -13704 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Node 1 sent an incremental fetch response for session 796767364 with 1 response partition(s), 1 implied partition(s)
[framework] 2020-06-22 08:52:04,154 - org.apache.kafka.clients.consumer.internals.Fetcher -13704 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Fetch READ_UNCOMMITTED at offset 65166 for partition topic1-1 returned fetch data (error=NONE, highWaterMark=65167, lastStableOffset = 65167, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=82)
[framework] 2020-06-22 08:52:04,155 - org.apache.kafka.clients.consumer.internals.Fetcher -13705 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-0 at position FetchPosition{offset=62129, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:04,155 - org.apache.kafka.clients.consumer.internals.Fetcher -13705 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Added READ_UNCOMMITTED fetch request for partition topic1-1 at position FetchPosition{offset=65167, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Kafka-1:9092 (id: 1 rack: null), epoch=0}} to node Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:04,155 - org.apache.kafka.clients.FetchSessionHandler -13705 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.FetchSessionHandler  - [Consumer clientId=consumer, groupId=DemoConsumer] Built incremental fetch (sessionId=796767364, epoch=28) for node 1. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 2 partition(s)
[framework] 2020-06-22 08:52:04,155 - org.apache.kafka.clients.consumer.internals.Fetcher -13705 [KafkaConsumerExample_name] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher  - [Consumer clientId=consumer, groupId=DemoConsumer] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(topic1-1), toForget=(), implied=(topic1-0)) to broker Kafka-1:9092 (id: 1 rack: null)
[framework] 2020-06-22 08:52:04,156 - org.apache.kafka.clients.consumer.KafkaConsumer -13706 [KafkaConsumerExample_name] INFO  org.apache.kafka.clients.consumer.KafkaConsumer  - [Consumer clientId=consumer, groupId=DemoConsumer] Subscribed to topic(s): topic1
